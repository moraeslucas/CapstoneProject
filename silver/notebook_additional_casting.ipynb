{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f37f7ad-f007-4215-af6f-aaac0750394d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import to_date, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "679d93d8-8ff0-4491-821f-4cfe0fa13c45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def parse_date(date):\n",
    "    try:\n",
    "        return pd.to_date(date,\n",
    "                          infer_datetime_format=True, # Inspect the 1st date strings and try to estimate the date format\n",
    "                          dayfirst=True, # It prefers to parse with day first (not strict)\n",
    "                          errors='coerce') # Returns NaT/missing values for the invalid parsing\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a74c8f60-6601-4937-b509-01f012e65dc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Using spark since its query runs/is distributed across the clusters, instead of Pandas (which runs on a single machine)\n",
    "df = spark.table(\"workspace.sc_silver.propostas_realizadas\") \\\n",
    "          .select(\"_fivetran_id\", \n",
    "                  \"data_de_validade_da_proposta\") \\\n",
    "          .where(\"data_de_validade_da_proposta IS NOT NULL\")\n",
    "\n",
    "#Using Pandas since its apply is employed for every single dataframe value\n",
    "pandas_df = df.toPandas()\n",
    "pandas_df[\"data_de_validade_da_proposta\"] = pandas_df[\"data_de_validade_da_proposta\"].apply(parse_date)\n",
    "\n",
    "parsed_df = spark.createDataFrame(pandas_df)\n",
    "parsed_df.createOrReplaceTempView(\"parsed_dates\")\n",
    "spark.sql(\"\"\"MERGE INTO workspace.sc_silver.propostas_realizadas AS target\n",
    "             USING parsed_dates AS source\n",
    "             ON target._fivetran_id = source._fivetran_id\n",
    "             WHEN MATCHED THEN \n",
    "                UPDATE SET target.data_de_validade_da_proposta = source.data_de_validade_da_proposta\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0da66bf5-fa2e-42ed-a7f8-b02fb1810bc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.table(\"workspace.sc_silver.propostas_realizadas\") \\\n",
    "          .withColumn(\"data_de_validade_da_proposta\", \n",
    "                      to_date(col(\"data_de_validade_da_proposta\"), \"d-M-yyyy\"))\n",
    "\n",
    "df.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"overwriteSchema\", \"true\") \\\n",
    "        .saveAsTable(\"workspace.sc_silver.propostas_realizadas\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "notebook_additional_casting",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
