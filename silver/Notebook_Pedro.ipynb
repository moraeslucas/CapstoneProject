{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b53e2bf-ed09-4a91-b2af-f270bb28b0cc",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"_fivetran_id\":154},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1754139395473}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM workspace.sc_silver.deals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0da8bf4a-a505-4bf7-9e17-c832411f7933",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM workspace.sc_silver.leads_pbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71bc9969-8339-4915-bd60-165523838d28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM workspace.sc_silver.campaigns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "baa46db1-f692-4d21-86a8-9384b294bd8e",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"id\":244},\"columnVisibility\":{}},\"settings\":{\"columns\":{\"link_centro_consentimento\":{\"format\":{\"preset\":\"string-preset-url\"}}}},\"syncTimestamp\":1754140174321}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM workspace.sc_silver.contactos_pbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e747fda-5d4a-41df-9e60-dc736b4bff86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT COUNT(*) AS num_duplicate_ids\n",
    "FROM (\n",
    "  SELECT id\n",
    "  FROM workspace.sc_silver.contactos_pbs\n",
    "  GROUP BY id\n",
    "  HAVING COUNT(*) > 1\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af68161b-a9ab-4168-a7ba-a5aa4be1fb93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT COUNT(*) AS num_duplicate_converted_contacts\n",
    "FROM (\n",
    "  SELECT converted_contact\n",
    "  FROM workspace.sc_silver.leads_pbs\n",
    "  WHERE converted_contact IS NOT NULL\n",
    "  GROUP BY converted_contact\n",
    "  HAVING COUNT(*) > 1\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "040e55c4-4b4b-447c-ae5c-e971b59f8eb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT COUNT(*) AS total_rows\n",
    "FROM workspace.sc_silver.leads_pbs;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85f3fdaf-be7d-4578-abfc-4fa407e5440b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT COUNT(id) AS non_null_ids\n",
    "FROM workspace.sc_silver.contactos_pbs;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "770b89d9-3896-4cf0-8fbf-0d48da9d4698",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT COUNT(DISTINCT c.id) AS common_unique_ids\n",
    "FROM workspace.sc_silver.contactos_pbs c\n",
    "JOIN workspace.sc_silver.leads_pbs l\n",
    "  ON c.id = l.converted_contact;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2dc00c9c-edee-462a-9076-05daa1e58f00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT COUNT(DISTINCT leads_pbs.converted_contact) AS common_ids_between_leads_and_campaigns\n",
    "FROM workspace.sc_silver.leads_pbs\n",
    "JOIN workspace.sc_silver.campaigns\n",
    "  ON leads_pbs.converted_contact = campaigns.id\n",
    "WHERE leads_pbs.converted_contact IS NOT NULL;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4c2b4f1-6c32-4fbb-848f-d8ae5b6eda3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Check which campaign IDs exist in leads.id\n",
    "SELECT DISTINCT id AS campaign_id_in_leads_id\n",
    "FROM workspace.sc_silver.campaigns\n",
    "WHERE id IN (\n",
    "  SELECT id FROM workspace.sc_silver.leads_pbs\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cf3642a-b177-4f6e-a306-efb5585eb957",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT\n",
    "  campaigns.id AS campaign_id,\n",
    "  CASE WHEN leads_by_id.id IS NOT NULL THEN 'Yes' ELSE 'No' END AS found_in_leads_id,\n",
    "  CASE WHEN leads_by_owner.lead_owner IS NOT NULL THEN 'Yes' ELSE 'No' END AS found_in_lead_owner\n",
    "FROM workspace.sc_silver.campaigns\n",
    "\n",
    "LEFT JOIN workspace.sc_silver.leads_pbs AS leads_by_id\n",
    "  ON campaigns.id = leads_by_id.id\n",
    "\n",
    "LEFT JOIN workspace.sc_silver.leads_pbs AS leads_by_owner\n",
    "  ON campaigns.id = leads_by_owner.lead_owner;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b39a6f10-579b-4704-a6a2-1d214c441ffc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT\n",
    "  campaigns.id AS campaign_id,\n",
    "  \n",
    "  -- Lookup flags\n",
    "  CASE WHEN leads_by_id.id IS NOT NULL THEN 'Yes' ELSE 'No' END AS found_in_leads_id,\n",
    "  CASE WHEN leads_by_owner.lead_owner IS NOT NULL THEN 'Yes' ELSE 'No' END AS found_in_lead_owner,\n",
    "\n",
    "  -- Add columns from leads_pbs\n",
    "  leads_by_id.id AS id_lead,\n",
    "  leads_by_id.converted_contact\n",
    "\n",
    "FROM workspace.sc_silver.campaigns\n",
    "\n",
    "-- Lookup campaigns.id in leads_pbs.id\n",
    "LEFT JOIN workspace.sc_silver.leads_pbs AS leads_by_id\n",
    "  ON campaigns.id = leads_by_id.id\n",
    "\n",
    "-- Lookup campaigns.id in leads_pbs.lead_owner\n",
    "LEFT JOIN workspace.sc_silver.leads_pbs AS leads_by_owner\n",
    "  ON campaigns.id = leads_by_owner.lead_owner;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68d5417f-3ef9-4021-bedd-c6a5dd1014a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT\n",
    "  c.id AS contacto_id,\n",
    "\n",
    "  -- Flags de correspondÃªncia\n",
    "  CASE WHEN p1.id IS NOT NULL THEN 'Yes' ELSE 'No' END AS match_with_proposta_id,\n",
    "  CASE WHEN p2.proposta_realizada_owner IS NOT NULL THEN 'Yes' ELSE 'No' END AS match_with_proposta_owner,\n",
    "  CASE WHEN p3.id_contacto IS NOT NULL THEN 'Yes' ELSE 'No' END AS match_with_id_contacto\n",
    "\n",
    "FROM workspace.sc_silver.contactos_pbs c\n",
    "\n",
    "-- Join com propostas_realizadas.id\n",
    "LEFT JOIN workspace.sc_silver.propostas_realizadas p1\n",
    "  ON c.id = p1.id\n",
    "\n",
    "-- Join com propostas_realizadas.proposta_realizada_owner\n",
    "LEFT JOIN workspace.sc_silver.propostas_realizadas p2\n",
    "  ON c.id = p2.proposta_realizada_owner\n",
    "\n",
    "-- Join com propostas_realizadas.id_contacto\n",
    "LEFT JOIN workspace.sc_silver.propostas_realizadas p3\n",
    "  ON c.id = p3.id_contacto;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f4a4dfc-8185-40c9-b5b1-1ddceb8f72f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT COUNT(DISTINCT p3.id_contacto) AS matching_contact_ids\n",
    "FROM workspace.sc_silver.propostas_realizadas p3\n",
    "JOIN workspace.sc_silver.contactos_pbs c\n",
    "    ON p3.id_contacto = c.id\n",
    "WHERE p3.id_contacto IS NOT NULL;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "877f105a-15fc-425a-b8f8-7fb7cb97e399",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT COUNT(DISTINCT p.id_contacto) AS matching_contact_ids\n",
    "FROM workspace.sc_silver.propostas_realizadas p\n",
    "JOIN workspace.sc_silver.deals d\n",
    "  ON p.id_contacto = d.id_contacto\n",
    "WHERE p.id_contacto IS NOT NULL;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40772d97-ca80-403b-9b8e-90775cc3df12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT COUNT(*) AS total_rows\n",
    "FROM workspace.sc_silver.leads_pbs;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efb312d8-bfa6-4333-afc2-0041125593b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT\n",
    "  l.converted_contact,\n",
    "  CASE WHEN d1.id IS NOT NULL THEN 'Yes' ELSE 'No' END AS match_in_deals_id,\n",
    "  CASE WHEN d2.converted_from_lead IS NOT NULL THEN 'Yes' ELSE 'No' END AS match_in_deals_converted_from_lead\n",
    "FROM workspace.sc_silver.leads_pbs l\n",
    "LEFT JOIN workspace.sc_silver.deals d1\n",
    "  ON l.converted_contact = d1.id\n",
    "LEFT JOIN workspace.sc_silver.deals d2\n",
    "  ON l.converted_contact = d2.converted_from_lead\n",
    "WHERE l.converted_contact IS NOT NULL;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c05c5c6-cea5-49dc-9c5b-227d505f9d71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- How many leads match deals.id\n",
    "SELECT COUNT(DISTINCT l.id) AS leads_in_deals_id\n",
    "FROM workspace.sc_silver.leads_pbs l\n",
    "JOIN workspace.sc_silver.deals d ON l.id = d.id;\n",
    "\n",
    "-- How many leads match deals.converted_from_lead\n",
    "SELECT COUNT(DISTINCT l.id) AS leads_in_converted_from_lead\n",
    "FROM workspace.sc_silver.leads_pbs l\n",
    "JOIN workspace.sc_silver.deals d ON l.id = d.converted_from_lead;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9b158d9-eda8-40e5-82af-21251baa5423",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT COUNT(DISTINCT d.campanha) AS matched_campaigns_in_deals\n",
    "FROM workspace.sc_silver.deals d\n",
    "JOIN workspace.sc_silver.campaigns c\n",
    "  ON d.campanha = c.id\n",
    "WHERE d.campanha IS NOT NULL;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "752c11c7-5fbd-4a30-a5f1-c026300f4c72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT COUNT(*) AS num_duplicate_converted_contacts\n",
    "FROM (\n",
    "  SELECT converted_contact\n",
    "  FROM workspace.sc_silver.leads_pbs\n",
    "  WHERE converted_contact IS NOT NULL\n",
    "  GROUP BY converted_contact\n",
    "  HAVING COUNT(*) > 1\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf3641f5-39a2-4882-b59e-0f1d6bbb9f44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT\n",
    "  occurrences,\n",
    "  COUNT(*) AS num_contacts_with_this_occurrence\n",
    "FROM (\n",
    "  SELECT converted_contact, COUNT(*) AS occurrences\n",
    "  FROM workspace.sc_silver.leads_pbs\n",
    "  WHERE converted_contact IS NOT NULL\n",
    "  GROUP BY converted_contact\n",
    ") AS sub\n",
    "GROUP BY occurrences\n",
    "ORDER BY occurrences;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cbdfbd9-f695-40f9-b957-60f06ab2e32f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT COUNT(*) AS num_duplicate_ids\n",
    "FROM (\n",
    "  SELECT id\n",
    "  FROM workspace.sc_silver.campaigns\n",
    "  GROUP BY id\n",
    "  HAVING COUNT(*) > 1\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "239fd20d-f91c-4e49-ab75-3d76e68d0e21",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"id_contacto\":199},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1754158993167}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT \n",
    "  id_contacto, \n",
    "  COUNT(*) AS occurrences\n",
    "FROM workspace.sc_silver.deals\n",
    "WHERE id_contacto IS NOT NULL\n",
    "GROUP BY id_contacto\n",
    "HAVING COUNT(*) > 1\n",
    "ORDER BY occurrences DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c635c88-131c-4748-a898-8cf952c06396",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "/*********************************************\n",
    "SELECT\n",
    "  COUNT(*) AS total_rows,\n",
    "  COUNT(CASE WHEN apoio_concessionario IS NULL THEN 1 END) * 100.0 / COUNT(*) AS pct_null_apoio_concessionario,\n",
    "  COUNT(CASE WHEN apoio_total IS NULL THEN 1 END) * 100.0 / COUNT(*) AS pct_null_apoio_total,\n",
    "  COUNT(CASE WHEN sub_total_com_extras IS NULL THEN 1 END) * 100.0 / COUNT(*) AS pct_null_sub_total_com_extras,\n",
    "  COUNT(CASE WHEN descricao_do_pedido_de_apoio IS NULL THEN 1 END) * 100.0 / COUNT(*) AS pct_null_descricao_do_pedido_de_apoio,\n",
    "  COUNT(CASE WHEN estado_do_pedido IS NULL THEN 1 END) * 100.0 / COUNT(*) AS pct_null_estado_do_pedido,\n",
    "  COUNT(CASE WHEN apoio_percentual IS NULL THEN 1 END) * 100.0 / COUNT(*) AS pct_null_apoio_percentual,\n",
    "  COUNT(CASE WHEN data_de_criacao_da_proposta IS NULL THEN 1 END) * 100.0 / COUNT(*) AS pct_null_data_de_criacao_da_proposta,\n",
    "  COUNT(CASE WHEN valor_campanhas_comerciais IS NULL THEN 1 END) * 100.0 / COUNT(*) AS pct_null_valor_campanhas_comerciais,\n",
    "  COUNT(CASE WHEN ofertas_de_campanha IS NULL THEN 1 END) * 100.0 / COUNT(*) AS pct_null_ofertas_de_campanha,\n",
    "  COUNT(CASE WHEN resposta_do_importador IS NULL THEN 1 END) * 100.0 / COUNT(*) AS pct_null_resposta_do_importador,\n",
    "  COUNT(CASE WHEN data_de_entrega_da_proposta IS NULL THEN 1 END) * 100.0 / COUNT(*) AS pct_null_data_de_entrega_da_proposta,\n",
    "  COUNT(CASE WHEN desconto_total__c__apoio_de_importador_ IS NULL THEN 1 END) * 100.0 / COUNT(*) AS pct_null_desconto_total__c__apoio_de_importador_,\n",
    "  COUNT(CASE WHEN codigo_cor_exterior IS NULL THEN 1 END) * 100.0 / COUNT(*) AS pct_null_codigo_cor_exterior,\n",
    "  COUNT(CASE WHEN codigo_cor_interior IS NULL THEN 1 END) * 100.0 / COUNT(*) AS pct_null_codigo_cor_interior,\n",
    "  COUNT(CASE WHEN concessionario_owner IS NULL THEN 1 END) * 100.0 / COUNT(*) AS pct_null_concessionario_owner,\n",
    "  COUNT(CASE WHEN valor_aprovado IS NULL THEN 1 END) * 100.0 / COUNT(*) AS pct_null_valor_aprovado,\n",
    "  COUNT(CASE WHEN estado_do_contrato IS NULL THEN 1 END) * 100.0 / COUNT(*) AS pct_null_estado_do_contrato,\n",
    "  COUNT(CASE WHEN data_prevista_matricula IS NULL THEN 1 END) * 100.0 / COUNT(*) AS pct_null_data_prevista_matricula,\n",
    "  COUNT(CASE WHEN data_prevista_de_entrega IS NULL THEN 1 END) * 100.0 / COUNT(*) AS pct_null_data_prevista_de_entrega,\n",
    "  COUNT(CASE WHEN data_da_conclusao IS NULL THEN 1 END) * 100.0 / COUNT(*) AS pct_null_data_da_conclusao,\n",
    "  COUNT(CASE WHEN id_classe IS NULL THEN 1 END) * 100.0 / COUNT(*) AS pct_null_id_classe,\n",
    "  COUNT(CASE WHEN descricao_classe IS NULL THEN 1 END) * 100.0 / COUNT(*) AS pct_null_descricao_classe,\n",
    "  COUNT(CASE WHEN id_model_group IS NULL THEN 1 END) * 100.0 / COUNT(*) AS pct_null_id_model_group,\n",
    "  COUNT(CASE WHEN descricao_model_group IS NULL THEN 1 END) * 100.0 / COUNT(*) AS pct_null_descricao_model_group,\n",
    "  COUNT(CASE WHEN valid_until IS NULL THEN 1 END) * 100.0 / COUNT(*) AS pct_null_valid_until,\n",
    "  COUNT(CASE WHEN forma_de_pagamento IS NULL THEN 1 END) * 100.0 / COUNT(*) AS pct_null_forma_de_pagamento,\n",
    "  COUNT(CASE WHEN nome_da_campanha IS NULL THEN 1 END) * 100.0 / COUNT(*) AS pct_null_nome_da_campanha,\n",
    "  COUNT(CASE WHEN _fivetran_index IS NULL THEN 1 END) * 100.0 / COUNT(*) AS pct_null_fivetran_index\n",
    "FROM workspace.sc_silver.propostas_realizadas;\n",
    "*********************************************/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02870a86-ac8e-4fe6-8f62-074b6c622b7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# ==== DEALS ====\n",
    "df_deals = spark.table(\"workspace.sc_silver.deals\")\n",
    "df_deals_renamed = df_deals.select(\n",
    "    *[F.col(c).alias(f\"{c}_deals\") for c in df_deals.columns]\n",
    ")\n",
    "df_deals_renamed.write.format(\"delta\").mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"workspace.sc_silver.deals_renamed\")\n",
    "display(spark.table(\"workspace.sc_silver.deals_renamed\"))\n",
    "\n",
    "# ==== CAMPAIGNS ====\n",
    "df_campaigns = spark.table(\"workspace.sc_silver.campaigns\")\n",
    "df_campaigns_renamed = df_campaigns.select(\n",
    "    *[F.col(c).alias(f\"{c}_campaigns\") for c in df_campaigns.columns]\n",
    ")\n",
    "df_campaigns_renamed.write.format(\"delta\").mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"workspace.sc_silver.campaigns_renamed\")\n",
    "display(spark.table(\"workspace.sc_silver.campaigns_renamed\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "844e4763-6fb6-43a6-8268-166f97cc6192",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"id_deals\":173},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1754781198428}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Load renamed tables\n",
    "df_deals_renamed = spark.table(\"workspace.sc_silver.deals_renamed\")\n",
    "df_campaigns_renamed = spark.table(\"workspace.sc_silver.campaigns_renamed\")\n",
    "\n",
    "# Join on campanha_deals = id_campaigns\n",
    "df_deals_with_campaigns = df_deals_renamed.join(\n",
    "    df_campaigns_renamed,\n",
    "    df_deals_renamed.campanha_deals == df_campaigns_renamed.id_campaigns,\n",
    "    \"left\"\n",
    ")\n",
    "\n",
    "# Save as permanent table\n",
    "df_deals_with_campaigns.write.format(\"delta\").mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"workspace.sc_silver.deals_with_campaigns\")\n",
    "\n",
    "# Preview\n",
    "display(spark.table(\"workspace.sc_silver.deals_with_campaigns\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1692a7c-cc66-43f2-85a4-7a8532afa851",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Load original table\n",
    "df = spark.table(\"workspace.sc_silver.propostas_realizadas\")\n",
    "\n",
    "# Build SELECT list with aliases (append _propostas_realizadas to each column)\n",
    "select_expr = [F.col(c).alias(f\"{c}_propostas_realizadas\") for c in df.columns]\n",
    "df_renamed = df.select(*select_expr)\n",
    "\n",
    "# Write to a NEW table so you don't overwrite original\n",
    "df_renamed.write.format(\"delta\").mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"workspace.sc_silver.propostas_realizadas_renamed\")\n",
    "\n",
    "# Display the new table\n",
    "display(spark.table(\"workspace.sc_silver.propostas_realizadas_renamed\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ad5d3fe-dec4-4fa8-b138-a61279acb433",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#  JOIN propostas_realizadas_renamed with deals_with_campaigns ====\n",
    "\n",
    "# Load both tables\n",
    "df_propostas_renamed = spark.table(\"workspace.sc_silver.propostas_realizadas_renamed\")\n",
    "df_deals_with_campaigns = spark.table(\"workspace.sc_silver.deals_with_campaigns\")\n",
    "\n",
    "# LEFT join from propostas to deals\n",
    "df_joined = df_propostas_renamed.join(\n",
    "    df_deals_with_campaigns,\n",
    "    df_propostas_renamed.id_contacto_propostas_realizadas == df_deals_with_campaigns.id_contacto_deals,\n",
    "    \"left\"\n",
    ")\n",
    "\n",
    "# Save as propostas_with_deals_with_campaigns\n",
    "df_joined.write.format(\"delta\").mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"workspace.sc_silver.propostas_with_deals_with_campaigns\")\n",
    "\n",
    "# Display the result\n",
    "display(spark.table(\"workspace.sc_silver.propostas_with_deals_with_campaigns\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4a5ef66-b9ea-4e7e-96a6-21d1139834ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM workspace.sc_silver.leads_pbs\n",
    "LIMIT 100;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c082d25-b8cd-4e5f-ad04-10e078790e21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM workspace.sc_silver.contactos_pbs\n",
    "LIMIT 100;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e72d128a-d830-47bc-821b-06cfa6d6427e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT COUNT(DISTINCT c.id) AS common_unique_ids\n",
    "FROM workspace.sc_silver.contactos_pbs c\n",
    "JOIN workspace.sc_silver.leads_pbs l\n",
    "  ON c.id = l.converted_contact;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6d5122c-68ca-4300-ae93-505c20107e88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "/*********************************************\n",
    "SELECT \n",
    "  COUNT(DISTINCT c.id) AS common_unique_ids,\n",
    "  COUNT(DISTINCT CASE \n",
    "    WHEN c.data_criacao_da_lead = l.created_time THEN c.id\n",
    "  END) AS common_unique_ids_with_date\n",
    "FROM workspace.sc_silver.contactos_pbs c\n",
    "JOIN workspace.sc_silver.leads_pbs l\n",
    "  ON c.id = l.converted_contact;\n",
    "  *********************************************/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe852c52-3991-4d96-ad61-4a3da88ea11b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# ==== LEADS ====\n",
    "df_leads = spark.table(\"workspace.sc_silver.leads_pbs\")\n",
    "df_leads_renamed = df_leads.select(\n",
    "    *[F.col(c).alias(f\"{c}_leads\") for c in df_leads.columns]\n",
    ")\n",
    "df_leads_renamed.write.format(\"delta\").mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"workspace.sc_silver.leads_renamed\")\n",
    "display(spark.table(\"workspace.sc_silver.leads_renamed\"))\n",
    "\n",
    "# ==== CONTACTOS ====\n",
    "df_contactos = spark.table(\"workspace.sc_silver.contactos_pbs\")\n",
    "df_contactos_renamed = df_contactos.select(\n",
    "    *[F.col(c).alias(f\"{c}_contactos\") for c in df_contactos.columns]\n",
    ")\n",
    "df_contactos_renamed.write.format(\"delta\").mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"workspace.sc_silver.contactos_renamed\")\n",
    "display(spark.table(\"workspace.sc_silver.contactos_renamed\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4440fa21-9b05-4eb5-a138-2257f6489e94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Load both renamed tables\n",
    "df_leads = spark.table(\"workspace.sc_silver.leads_renamed\")\n",
    "df_contactos = spark.table(\"workspace.sc_silver.contactos_renamed\")\n",
    "\n",
    "# LEFT join on both ID and date\n",
    "df_joined = df_leads.join(\n",
    "    df_contactos,\n",
    "    (df_leads.converted_contact_leads == df_contactos.id_contactos) &\n",
    "    (F.to_timestamp(df_leads.created_time_leads, \"dd-MM-yyyy HH:mm\") ==\n",
    "     F.to_timestamp(df_contactos.data_criacao_da_lead_contactos, \"dd-MM-yyyy HH:mm\")),\n",
    "    \"left\"\n",
    ")\n",
    "\n",
    "# Save as a new permanent table\n",
    "df_joined.write.format(\"delta\").mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"workspace.sc_silver.leads_with_contactos\")\n",
    "\n",
    "# Display preview\n",
    "display(spark.table(\"workspace.sc_silver.leads_with_contactos\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a41473d-e99b-4d97-ae11-a2e28f53b083",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Load the new table\n",
    "df_new = spark.table(\"workspace.sc_silver.leads_with_contactos\")\n",
    "\n",
    "# Calculate the counts\n",
    "df_counts = df_new.agg(\n",
    "    F.countDistinct(\"id_contactos\").alias(\"common_unique_ids\"),\n",
    "    F.countDistinct(\n",
    "        F.when(\n",
    "            F.to_timestamp(df_new.data_criacao_da_lead_contactos, \"dd-MM-yyyy HH:mm\") ==\n",
    "            F.to_timestamp(df_new.created_time_leads, \"dd-MM-yyyy HH:mm\"),\n",
    "            df_new.id_contactos\n",
    "        )\n",
    "    ).alias(\"common_unique_ids_with_date\")\n",
    ")\n",
    "\n",
    "df_counts.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "154578c7-4b4b-4d53-a7cf-748fc15df069",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1754779373958}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "SELECT *\n",
    "FROM workspace.sc_silver.propostas_with_deals_with_campaigns\n",
    "LIMIT 100;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37e5de9d-af4b-41ba-b597-902b8cb138e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- First table\n",
    "SELECT *\n",
    "FROM workspace.sc_silver.leads_with_contactos\n",
    "LIMIT 100;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52c690d9-c762-4aa5-9458-80b8efe2b71b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Load both tables\n",
    "df_leads_contactos = spark.table(\"workspace.sc_silver.leads_with_contactos\")\n",
    "df_propostas = spark.table(\"workspace.sc_silver.propostas_with_deals_with_campaigns\")\n",
    "\n",
    "# LEFT join on id_contactos vs id_contacto_propostas_realizadas\n",
    "df_funil = df_leads_contactos.join(\n",
    "    df_propostas,\n",
    "    df_leads_contactos.id_contactos == df_propostas.id_contacto_propostas_realizadas,\n",
    "    \"left\"\n",
    ")\n",
    "\n",
    "# Save as permanent table\n",
    "df_funil.write.format(\"delta\").mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"workspace.sc_silver.Funil\")\n",
    "\n",
    "# Preview\n",
    "display(spark.table(\"workspace.sc_silver.Funil\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3512ab46-afb6-4fca-aad1-8d71f9677b5f",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"tableName\":285},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1754781317091}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SHOW TABLES IN workspace.sc_silver;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c977a483-19bb-49ff-b247-6731de4ec0be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39f0a509-6f6a-4113-9824-5fd8c190a066",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import (\n",
    "    StringType, DoubleType, FloatType\n",
    ")\n",
    "\n",
    "# Load table\n",
    "df = spark.table(\"sc_silver.funil\")\n",
    "\n",
    "total_rows = df.count()\n",
    "if total_rows == 0:\n",
    "    spark.createDataFrame([], \"column string, blank_pct double\").show()\n",
    "else:\n",
    "    # Build one aggregation per column\n",
    "    agg_exprs = []\n",
    "    col_names = []\n",
    "    for field in df.schema.fields:\n",
    "        c = field.name\n",
    "        dt = field.dataType\n",
    "\n",
    "        if isinstance(dt, StringType):\n",
    "            # NULL or empty/whitespace\n",
    "            cond = F.col(c).isNull() | (F.length(F.trim(F.col(c))) == 0)\n",
    "        elif isinstance(dt, (DoubleType, FloatType)):\n",
    "            # NULL or NaN\n",
    "            cond = F.col(c).isNull() | F.isnan(F.col(c))\n",
    "        else:\n",
    "            # Other types: only NULL counts as blank\n",
    "            cond = F.col(c).isNull()\n",
    "\n",
    "        agg_exprs.append(F.round(F.avg(F.when(cond, 1).otherwise(0)) * 100, 4).alias(c))\n",
    "        col_names.append(c)\n",
    "\n",
    "    # One row with % per column\n",
    "    pct_row = df.agg(*agg_exprs)\n",
    "\n",
    "    # Reshape to (column, blank_pct)\n",
    "    stack_expr = \", \".join([f\"'{c}', `{c}`\" for c in col_names])\n",
    "    tidy = pct_row.selectExpr(f\"stack({len(col_names)}, {stack_expr}) as (column, blank_pct)\")\n",
    "\n",
    "    tidy.orderBy(F.desc(\"blank_pct\")).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "102ff5ee-7ba3-4546-bd56-42a865ad6231",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tidy.orderBy(F.desc(\"blank_pct\")).show(n=tidy.count(), truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abd47814-4ddc-4912-94cb-48585ea718d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType, DoubleType, FloatType\n",
    "\n",
    "tables = [\n",
    "    \"bd_rede_hyundai\",\n",
    "    \"campanha_vouchers\",\n",
    "    \"campanhas_tecnicas\",\n",
    "    \"contactos_importador_pbs\",\n",
    "    \"contratos_financiamento\",\n",
    "    \"historico_de_servicos\",\n",
    "    \"viaturas\",\n",
    "    \"viaturas_demo\"\n",
    "]\n",
    "\n",
    "def blank_percentage_for_table(table_name):\n",
    "    print(f\"=== Processing table: {table_name} ===\")\n",
    "    df = spark.table(f\"sc_silver.{table_name}\")\n",
    "    total_rows = df.count()\n",
    "\n",
    "    if total_rows == 0:\n",
    "        print(f\"Table {table_name} is empty.\")\n",
    "        return spark.createDataFrame([], \"column string, blank_pct double\")\n",
    "\n",
    "    agg_exprs = []\n",
    "    col_names = []\n",
    "\n",
    "    for field in df.schema.fields:\n",
    "        c = field.name\n",
    "        dt = field.dataType\n",
    "\n",
    "        if isinstance(dt, StringType):\n",
    "            cond = F.col(c).isNull() | (F.length(F.trim(F.col(c))) == 0)\n",
    "        elif isinstance(dt, (DoubleType, FloatType)):\n",
    "            cond = F.col(c).isNull() | F.isnan(F.col(c))\n",
    "        else:\n",
    "            cond = F.col(c).isNull()\n",
    "\n",
    "        agg_exprs.append(F.round(F.avg(F.when(cond, 1).otherwise(0)) * 100, 4).alias(c))\n",
    "        col_names.append(c)\n",
    "\n",
    "    pct_row = df.agg(*agg_exprs)\n",
    "    stack_expr = \", \".join([f\"'{c}', `{c}`\" for c in col_names])\n",
    "    tidy = pct_row.selectExpr(f\"stack({len(col_names)}, {stack_expr}) as (column, blank_pct)\")\n",
    "\n",
    "    return tidy.orderBy(F.desc(\"blank_pct\"))\n",
    "\n",
    "# Loop through all tables and show results\n",
    "for tbl in tables:\n",
    "    result_df = blank_percentage_for_table(tbl)\n",
    "    result_df.show(n=result_df.count(), truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a09a8c8-ded9-4279-9734-87d0d1e462a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.bd_rede_hyundai;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf7db9c3-a6f3-4cbf-a3ac-de82e5302d28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.campanha_vouchers;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31860eda-6da3-46bd-8e9b-54db7ad5e38a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.campanhas_tecnicas;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e43bba88-1c6e-49f6-834c-327b281f2a99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.contactos_importador_pbs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3df4acea-89f5-4076-ab58-07c0088a9eea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.contactos_pbs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd4486f1-6115-4ed0-971c-ea9588728174",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.contas_importador_pbs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1bb6844-a80f-46fd-81cc-738937394b08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.contas_pbs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "382c3ef1-1c8b-496c-a458-38274e6a1e4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.contratos_financiamento;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "124e9bb7-2445-4d2f-957f-b186666d3d34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.deals;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23f63356-8a1d-4693-82f9-17cefe7884c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.historico_de_servicos;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f83d8e43-9728-4a53-9e4e-9586871efb97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.leads_pbs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a6670a8-eaea-42ff-bdc7-03d3428f7a2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.propostas_realizadas;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "070c4055-aaae-4d1d-95a8-1f366ebb432b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.viaturas;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f626932f-3330-4a22-a3a6-5e55f7f11762",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.viaturas_demo;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a15386ac-ee50-42cd-be82-ddc5aed4d8f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import (\n",
    "    StringType, DoubleType, FloatType\n",
    ")\n",
    "\n",
    "# Load table\n",
    "df = spark.table(\"sc_silver.bd_rede_hyundai\")\n",
    "\n",
    "total_rows = df.count()\n",
    "if total_rows == 0:\n",
    "    spark.createDataFrame([], \"column string, blank_pct double\").show()\n",
    "else:\n",
    "    # Build one aggregation per column\n",
    "    agg_exprs = []\n",
    "    col_names = []\n",
    "    for field in df.schema.fields:\n",
    "        c = field.name\n",
    "        dt = field.dataType\n",
    "\n",
    "        if isinstance(dt, StringType):\n",
    "            # NULL or empty/whitespace\n",
    "            cond = F.col(c).isNull() | (F.length(F.trim(F.col(c))) == 0)\n",
    "        elif isinstance(dt, (DoubleType, FloatType)):\n",
    "            # NULL or NaN\n",
    "            cond = F.col(c).isNull() | F.isnan(F.col(c))\n",
    "        else:\n",
    "            # Other types: only NULL counts as blank\n",
    "            cond = F.col(c).isNull()\n",
    "\n",
    "        agg_exprs.append(F.round(F.avg(F.when(cond, 1).otherwise(0)) * 100, 4).alias(c))\n",
    "        col_names.append(c)\n",
    "\n",
    "    # One row with % per column\n",
    "    pct_row = df.agg(*agg_exprs)\n",
    "\n",
    "    # Reshape to (column, blank_pct)\n",
    "    stack_expr = \", \".join([f\"'{c}', `{c}`\" for c in col_names])\n",
    "    tidy = pct_row.selectExpr(f\"stack({len(col_names)}, {stack_expr}) as (column, blank_pct)\")\n",
    "\n",
    "    tidy.orderBy(F.desc(\"blank_pct\")).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf3e9639-7c53-42f4-a4a6-44345fb85ea2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import (\n",
    "    StringType, DoubleType, FloatType\n",
    ")\n",
    "\n",
    "# Load table\n",
    "df = spark.table(\"sc_silver.campaigns\")\n",
    "\n",
    "total_rows = df.count()\n",
    "if total_rows == 0:\n",
    "    spark.createDataFrame([], \"column string, blank_pct double\").show()\n",
    "else:\n",
    "    # Build one aggregation per column\n",
    "    agg_exprs = []\n",
    "    col_names = []\n",
    "    for field in df.schema.fields:\n",
    "        c = field.name\n",
    "        dt = field.dataType\n",
    "\n",
    "        if isinstance(dt, StringType):\n",
    "            # NULL or empty/whitespace\n",
    "            cond = F.col(c).isNull() | (F.length(F.trim(F.col(c))) == 0)\n",
    "        elif isinstance(dt, (DoubleType, FloatType)):\n",
    "            # NULL or NaN\n",
    "            cond = F.col(c).isNull() | F.isnan(F.col(c))\n",
    "        else:\n",
    "            # Other types: only NULL counts as blank\n",
    "            cond = F.col(c).isNull()\n",
    "\n",
    "        agg_exprs.append(F.round(F.avg(F.when(cond, 1).otherwise(0)) * 100, 4).alias(c))\n",
    "        col_names.append(c)\n",
    "\n",
    "    # One row with % per column\n",
    "    pct_row = df.agg(*agg_exprs)\n",
    "\n",
    "    # Reshape to (column, blank_pct)\n",
    "    stack_expr = \", \".join([f\"'{c}', `{c}`\" for c in col_names])\n",
    "    tidy = pct_row.selectExpr(f\"stack({len(col_names)}, {stack_expr}) as (column, blank_pct)\")\n",
    "\n",
    "    tidy.orderBy(F.desc(\"blank_pct\")).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b89a271b-db6c-43eb-8760-fe6d4afc056f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import (\n",
    "    StringType, DoubleType, FloatType\n",
    ")\n",
    "\n",
    "# Load table\n",
    "df = spark.table(\"sc_silver.campanha_vouchers\")\n",
    "\n",
    "total_rows = df.count()\n",
    "if total_rows == 0:\n",
    "    spark.createDataFrame([], \"column string, blank_pct double\").show()\n",
    "else:\n",
    "    # Build one aggregation per column\n",
    "    agg_exprs = []\n",
    "    col_names = []\n",
    "    for field in df.schema.fields:\n",
    "        c = field.name\n",
    "        dt = field.dataType\n",
    "\n",
    "        if isinstance(dt, StringType):\n",
    "            # NULL or empty/whitespace\n",
    "            cond = F.col(c).isNull() | (F.length(F.trim(F.col(c))) == 0)\n",
    "        elif isinstance(dt, (DoubleType, FloatType)):\n",
    "            # NULL or NaN\n",
    "            cond = F.col(c).isNull() | F.isnan(F.col(c))\n",
    "        else:\n",
    "            # Other types: only NULL counts as blank\n",
    "            cond = F.col(c).isNull()\n",
    "\n",
    "        agg_exprs.append(F.round(F.avg(F.when(cond, 1).otherwise(0)) * 100, 4).alias(c))\n",
    "        col_names.append(c)\n",
    "\n",
    "    # One row with % per column\n",
    "    pct_row = df.agg(*agg_exprs)\n",
    "\n",
    "    # Reshape to (column, blank_pct)\n",
    "    stack_expr = \", \".join([f\"'{c}', `{c}`\" for c in col_names])\n",
    "    tidy = pct_row.selectExpr(f\"stack({len(col_names)}, {stack_expr}) as (column, blank_pct)\")\n",
    "\n",
    "    tidy.orderBy(F.desc(\"blank_pct\")).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2870097-89b6-442f-9a09-6c98bcc0cfa0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import (\n",
    "    StringType, DoubleType, FloatType\n",
    ")\n",
    "\n",
    "# Load table\n",
    "df = spark.table(\"sc_silver.campanhas_tecnicas\")\n",
    "\n",
    "total_rows = df.count()\n",
    "if total_rows == 0:\n",
    "    spark.createDataFrame([], \"column string, blank_pct double\").show()\n",
    "else:\n",
    "    # Build one aggregation per column\n",
    "    agg_exprs = []\n",
    "    col_names = []\n",
    "    for field in df.schema.fields:\n",
    "        c = field.name\n",
    "        dt = field.dataType\n",
    "\n",
    "        if isinstance(dt, StringType):\n",
    "            # NULL or empty/whitespace\n",
    "            cond = F.col(c).isNull() | (F.length(F.trim(F.col(c))) == 0)\n",
    "        elif isinstance(dt, (DoubleType, FloatType)):\n",
    "            # NULL or NaN\n",
    "            cond = F.col(c).isNull() | F.isnan(F.col(c))\n",
    "        else:\n",
    "            # Other types: only NULL counts as blank\n",
    "            cond = F.col(c).isNull()\n",
    "\n",
    "        agg_exprs.append(F.round(F.avg(F.when(cond, 1).otherwise(0)) * 100, 4).alias(c))\n",
    "        col_names.append(c)\n",
    "\n",
    "    # One row with % per column\n",
    "    pct_row = df.agg(*agg_exprs)\n",
    "\n",
    "    # Reshape to (column, blank_pct)\n",
    "    stack_expr = \", \".join([f\"'{c}', `{c}`\" for c in col_names])\n",
    "    tidy = pct_row.selectExpr(f\"stack({len(col_names)}, {stack_expr}) as (column, blank_pct)\")\n",
    "\n",
    "    tidy.orderBy(F.desc(\"blank_pct\")).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79f26b00-c99d-4c14-8b4c-21a78622ebaf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType, DoubleType, FloatType\n",
    "\n",
    "# ---------- Config ----------\n",
    "table_name = \"sc_silver.contactos_importador_pbs\"  # <- change if needed\n",
    "only_above_pct = None  # e.g. set to 0 or 50 to filter; use None to show ALL\n",
    "# ----------------------------\n",
    "\n",
    "df = spark.table(table_name)\n",
    "\n",
    "total_rows = df.count()\n",
    "if total_rows == 0:\n",
    "    print(f\"{table_name} is empty.\")\n",
    "    spark.createDataFrame([], \"column string, blank_pct double\").show()\n",
    "else:\n",
    "    # Build one aggregation per column\n",
    "    agg_exprs, col_names = [], []\n",
    "    for field in df.schema.fields:\n",
    "        c = field.name\n",
    "        dt = field.dataType\n",
    "\n",
    "        if isinstance(dt, StringType):\n",
    "            # NULL or empty/whitespace\n",
    "            cond = F.col(c).isNull() | (F.length(F.trim(F.col(c))) == 0)\n",
    "        elif isinstance(dt, (DoubleType, FloatType)):\n",
    "            # NULL or NaN\n",
    "            cond = F.col(c).isNull() | F.isnan(F.col(c))\n",
    "        else:\n",
    "            # Other types: only NULL counts as blank\n",
    "            cond = F.col(c).isNull()\n",
    "\n",
    "        agg_exprs.append(F.round(F.avg(F.when(cond, 1).otherwise(0)) * 100, 4).alias(c))\n",
    "        col_names.append(c)\n",
    "\n",
    "    # One row with % per column\n",
    "    pct_row = df.agg(*agg_exprs)\n",
    "\n",
    "    # Reshape to (column, blank_pct)\n",
    "    stack_expr = \", \".join([f\"'{c}', `{c}`\" for c in col_names])\n",
    "    tidy = pct_row.selectExpr(f\"stack({len(col_names)}, {stack_expr}) as (column, blank_pct)\")\n",
    "\n",
    "    # Optional filter\n",
    "    if only_above_pct is not None:\n",
    "        tidy = tidy.filter(F.col(\"blank_pct\") > float(only_above_pct))\n",
    "\n",
    "    tidy = tidy.orderBy(F.desc(\"blank_pct\"))\n",
    "\n",
    "    # >>> Show ALL rows\n",
    "    tidy.show(tidy.count(), truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0632d8e-13c7-4556-b9e0-94d62c11b730",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "spark.table(\"sc_silver.contactos_importador_pbs\") \\\n",
    "    .select(\"pais\") \\\n",
    "    .distinct() \\\n",
    "    .show(truncate=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdd58d0d-ed34-4f63-b777-7370977ca6eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "spark.table(\"sc_silver.contactos_importador_pbs\") \\\n",
    "    .groupBy(\"pais\") \\\n",
    "    .count() \\\n",
    "    .orderBy(F.desc(\"count\")) \\\n",
    "    .show(truncate=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a7b16fc-1d6c-449f-8bf9-ad16479bb8ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType, DoubleType, FloatType\n",
    "\n",
    "# ---------- Config ----------\n",
    "table_name = \"sc_silver.contactos_pbs\"  # <- changed to contactos_pbs\n",
    "only_above_pct = None  # e.g. set to 0 or 50 to filter; use None to show ALL\n",
    "# ----------------------------\n",
    "\n",
    "df = spark.table(table_name)\n",
    "\n",
    "total_rows = df.count()\n",
    "if total_rows == 0:\n",
    "    print(f\"{table_name} is empty.\")\n",
    "    spark.createDataFrame([], \"column string, blank_pct double\").show()\n",
    "else:\n",
    "    # Build one aggregation per column\n",
    "    agg_exprs, col_names = [], []\n",
    "    for field in df.schema.fields:\n",
    "        c = field.name\n",
    "        dt = field.dataType\n",
    "\n",
    "        if isinstance(dt, StringType):\n",
    "            # NULL or empty/whitespace\n",
    "            cond = F.col(c).isNull() | (F.length(F.trim(F.col(c))) == 0)\n",
    "        elif isinstance(dt, (DoubleType, FloatType)):\n",
    "            # NULL or NaN\n",
    "            cond = F.col(c).isNull() | F.isnan(F.col(c))\n",
    "        else:\n",
    "            # Other types: only NULL counts as blank\n",
    "            cond = F.col(c).isNull()\n",
    "\n",
    "        agg_exprs.append(F.round(F.avg(F.when(cond, 1).otherwise(0)) * 100, 4).alias(c))\n",
    "        col_names.append(c)\n",
    "\n",
    "    # One row with % per column\n",
    "    pct_row = df.agg(*agg_exprs)\n",
    "\n",
    "    # Reshape to (column, blank_pct)\n",
    "    stack_expr = \", \".join([f\"'{c}', `{c}`\" for c in col_names])\n",
    "    tidy = pct_row.selectExpr(f\"stack({len(col_names)}, {stack_expr}) as (column, blank_pct)\")\n",
    "\n",
    "    # Optional filter\n",
    "    if only_above_pct is not None:\n",
    "        tidy = tidy.filter(F.col(\"blank_pct\") > float(only_above_pct))\n",
    "\n",
    "    tidy = tidy.orderBy(F.desc(\"blank_pct\"))\n",
    "\n",
    "    # >>> Show ALL rows\n",
    "    tidy.show(tidy.count(), truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "719ed1b5-0e14-42d6-a295-4cd9c973b393",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType, DoubleType, FloatType\n",
    "\n",
    "# ---------- Config ----------\n",
    "table_name = \"sc_silver.contas_importador_pbs\"  # <- changed to contas_importador_pbs\n",
    "only_above_pct = None  # e.g. set to 0 or 50 to filter; use None to show ALL\n",
    "# ----------------------------\n",
    "\n",
    "df = spark.table(table_name)\n",
    "\n",
    "total_rows = df.count()\n",
    "if total_rows == 0:\n",
    "    print(f\"{table_name} is empty.\")\n",
    "    spark.createDataFrame([], \"column string, blank_pct double\").show()\n",
    "else:\n",
    "    # Build one aggregation per column\n",
    "    agg_exprs, col_names = [], []\n",
    "    for field in df.schema.fields:\n",
    "        c = field.name\n",
    "        dt = field.dataType\n",
    "\n",
    "        if isinstance(dt, StringType):\n",
    "            # NULL or empty/whitespace\n",
    "            cond = F.col(c).isNull() | (F.length(F.trim(F.col(c))) == 0)\n",
    "        elif isinstance(dt, (DoubleType, FloatType)):\n",
    "            # NULL or NaN\n",
    "            cond = F.col(c).isNull() | F.isnan(F.col(c))\n",
    "        else:\n",
    "            # Other types: only NULL counts as blank\n",
    "            cond = F.col(c).isNull()\n",
    "\n",
    "        agg_exprs.append(F.round(F.avg(F.when(cond, 1).otherwise(0)) * 100, 4).alias(c))\n",
    "        col_names.append(c)\n",
    "\n",
    "    # One row with % per column\n",
    "    pct_row = df.agg(*agg_exprs)\n",
    "\n",
    "    # Reshape to (column, blank_pct)\n",
    "    stack_expr = \", \".join([f\"'{c}', `{c}`\" for c in col_names])\n",
    "    tidy = pct_row.selectExpr(f\"stack({len(col_names)}, {stack_expr}) as (column, blank_pct)\")\n",
    "\n",
    "    # Optional filter\n",
    "    if only_above_pct is not None:\n",
    "        tidy = tidy.filter(F.col(\"blank_pct\") > float(only_above_pct))\n",
    "\n",
    "    tidy = tidy.orderBy(F.desc(\"blank_pct\"))\n",
    "\n",
    "    # >>> Show ALL rows\n",
    "    tidy.show(tidy.count(), truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af09f545-056f-4e46-9b44-f1862c96d020",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType, DoubleType, FloatType\n",
    "\n",
    "# ---------- Config ----------\n",
    "table_name = \"sc_silver.contas_pbs\"  # <- changed to contas_pbs\n",
    "only_above_pct = None  # e.g. set to 0 or 50 to filter; use None to show ALL\n",
    "# ----------------------------\n",
    "\n",
    "df = spark.table(table_name)\n",
    "\n",
    "total_rows = df.count()\n",
    "if total_rows == 0:\n",
    "    print(f\"{table_name} is empty.\")\n",
    "    spark.createDataFrame([], \"column string, blank_pct double\").show()\n",
    "else:\n",
    "    # Build one aggregation per column\n",
    "    agg_exprs, col_names = [], []\n",
    "    for field in df.schema.fields:\n",
    "        c = field.name\n",
    "        dt = field.dataType\n",
    "\n",
    "        if isinstance(dt, StringType):\n",
    "            # NULL or empty/whitespace\n",
    "            cond = F.col(c).isNull() | (F.length(F.trim(F.col(c))) == 0)\n",
    "        elif isinstance(dt, (DoubleType, FloatType)):\n",
    "            # NULL or NaN\n",
    "            cond = F.col(c).isNull() | F.isnan(F.col(c))\n",
    "        else:\n",
    "            # Other types: only NULL counts as blank\n",
    "            cond = F.col(c).isNull()\n",
    "\n",
    "        agg_exprs.append(F.round(F.avg(F.when(cond, 1).otherwise(0)) * 100, 4).alias(c))\n",
    "        col_names.append(c)\n",
    "\n",
    "    # One row with % per column\n",
    "    pct_row = df.agg(*agg_exprs)\n",
    "\n",
    "    # Reshape to (column, blank_pct)\n",
    "    stack_expr = \", \".join([f\"'{c}', `{c}`\" for c in col_names])\n",
    "    tidy = pct_row.selectExpr(f\"stack({len(col_names)}, {stack_expr}) as (column, blank_pct)\")\n",
    "\n",
    "    # Optional filter\n",
    "    if only_above_pct is not None:\n",
    "        tidy = tidy.filter(F.col(\"blank_pct\") > float(only_above_pct))\n",
    "\n",
    "    tidy = tidy.orderBy(F.desc(\"blank_pct\"))\n",
    "\n",
    "    # >>> Show ALL rows\n",
    "    tidy.show(tidy.count(), truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "017c8a1a-d6c5-4fe3-822e-eec8cdfe2c9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "table = \"sc_silver.contas_pbs\"\n",
    "cols = [\"tasks_involved\", \"events_involved\", \"calls_involved\", \"rent_a_car\"]\n",
    "\n",
    "df = spark.table(table)\n",
    "total = df.count()\n",
    "\n",
    "# Only keep columns that actually exist (avoid errors)\n",
    "present = [c for c in cols if c in df.columns]\n",
    "missing = [c for c in cols if c not in df.columns]\n",
    "if missing:\n",
    "    print(\"Skipping missing columns:\", \", \".join(missing))\n",
    "\n",
    "for c in present:\n",
    "    print(f\"\\n=== {c} ===\")\n",
    "    # Treat NULLs explicitly so they show up in counts\n",
    "    out = (\n",
    "        df.groupBy(F.coalesce(F.col(c).cast(\"string\"), F.lit(\"<NULL>\")).alias(c))\n",
    "          .count()\n",
    "          .withColumn(\"pct\", F.round(F.col(\"count\") / F.lit(total) * 100, 2))\n",
    "          .orderBy(F.desc(\"count\"))\n",
    "    )\n",
    "    out.show(out.count(), truncate=False)  # show all rows for this column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8245677c-e538-4bdf-8d6f-c0b168cdac50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Table to profile\n",
    "table_name = \"sc_silver.contratos_financiamento\"\n",
    "\n",
    "df = spark.table(table_name)\n",
    "total_rows = df.count()\n",
    "\n",
    "if total_rows == 0:\n",
    "    print(f\"{table_name} is empty.\")\n",
    "else:\n",
    "    cols = df.columns\n",
    "\n",
    "    # One pass: compute NULL counts for every column\n",
    "    agg_exprs = [\n",
    "        F.sum(F.when(F.col(c).isNull(), 1).otherwise(0)).alias(c) for c in cols\n",
    "    ]\n",
    "    null_counts_row = df.agg(*agg_exprs)\n",
    "\n",
    "    # Reshape to (column, null_count) and add percentage\n",
    "    stack_expr = \", \".join([f\"'{c}', `{c}`\" for c in cols])\n",
    "    out = (\n",
    "        null_counts_row.selectExpr(f\"stack({len(cols)}, {stack_expr}) as (column, null_count)\")\n",
    "        .withColumn(\"total_rows\", F.lit(total_rows))\n",
    "        .withColumn(\"null_pct\", F.round(F.col(\"null_count\") / F.col(\"total_rows\") * 100, 4))\n",
    "        .orderBy(F.desc(\"null_pct\"), F.desc(\"null_count\"))\n",
    "    )\n",
    "\n",
    "    # Show all rows\n",
    "    out.show(out.count(), truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "676cc592-8b9a-4aa1-9d3e-fa40a569c39d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Table to profile\n",
    "table_name = \"sc_silver.deals\"\n",
    "\n",
    "df = spark.table(table_name)\n",
    "total_rows = df.count()\n",
    "\n",
    "if total_rows == 0:\n",
    "    print(f\"{table_name} is empty.\")\n",
    "else:\n",
    "    cols = df.columns\n",
    "\n",
    "    # One pass: compute NULL counts for every column\n",
    "    agg_exprs = [F.sum(F.when(F.col(c).isNull(), 1).otherwise(0)).alias(c) for c in cols]\n",
    "    null_counts_row = df.agg(*agg_exprs)\n",
    "\n",
    "    # Reshape to (column, null_count) and add percentage\n",
    "    stack_expr = \", \".join([f\"'{c}', `{c}`\" for c in cols])\n",
    "    out = (\n",
    "        null_counts_row.selectExpr(f\"stack({len(cols)}, {stack_expr}) as (column, null_count)\")\n",
    "        .withColumn(\"total_rows\", F.lit(total_rows))\n",
    "        .withColumn(\"null_pct\", F.round(F.col(\"null_count\") / F.col(\"total_rows\") * 100, 4))\n",
    "        .orderBy(F.desc(\"null_pct\"), F.desc(\"null_count\"))\n",
    "    )\n",
    "\n",
    "    # Show all rows\n",
    "    out.show(out.count(), truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3544be60-963d-4125-b75a-ba22a1fb0427",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Table to profile\n",
    "table_name = \"sc_silver.historico_de_servicos\"\n",
    "\n",
    "df = spark.table(table_name)\n",
    "total_rows = df.count()\n",
    "\n",
    "if total_rows == 0:\n",
    "    print(f\"{table_name} is empty.\")\n",
    "else:\n",
    "    cols = df.columns\n",
    "\n",
    "    # One pass: compute NULL counts for every column\n",
    "    agg_exprs = [F.sum(F.when(F.col(c).isNull(), 1).otherwise(0)).alias(c) for c in cols]\n",
    "    null_counts_row = df.agg(*agg_exprs)\n",
    "\n",
    "    # Reshape to (column, null_count) and add percentage\n",
    "    stack_expr = \", \".join([f\"'{c}', `{c}`\" for c in cols])\n",
    "    out = (\n",
    "        null_counts_row.selectExpr(f\"stack({len(cols)}, {stack_expr}) as (column, null_count)\")\n",
    "        .withColumn(\"total_rows\", F.lit(total_rows))\n",
    "        .withColumn(\"null_pct\", F.round(F.col(\"null_count\") / F.col(\"total_rows\") * 100, 4))\n",
    "        .orderBy(F.desc(\"null_pct\"), F.desc(\"null_count\"))\n",
    "    )\n",
    "\n",
    "    # Show all rows\n",
    "    out.show(out.count(), truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4c4de6c-0337-4a40-90c6-5d4b58ff66d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "table = \"sc_silver.historico_de_servicos\"\n",
    "cols = [\"ciclo_de_fidelizacao\", \"dadosconcessao\"]\n",
    "\n",
    "df = spark.table(table)\n",
    "total = df.count()\n",
    "\n",
    "# Only keep columns that actually exist (avoid errors)\n",
    "present = [c for c in cols if c in df.columns]\n",
    "missing = [c for c in cols if c not in df.columns]\n",
    "if missing:\n",
    "    print(\"Skipping missing columns:\", \", \".join(missing))\n",
    "\n",
    "for c in present:\n",
    "    print(f\"\\n=== {c} ===\")\n",
    "    # Treat NULLs explicitly so they show up in counts\n",
    "    out = (\n",
    "        df.groupBy(F.coalesce(F.col(c).cast(\"string\"), F.lit(\"<NULL>\")).alias(c))\n",
    "          .count()\n",
    "          .withColumn(\"pct\", F.round(F.col(\"count\") / F.lit(total) * 100, 2))\n",
    "          .orderBy(F.desc(\"count\"))\n",
    "    )\n",
    "    out.show(out.count(), truncate=False)  # show all rows for this column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3613d99-64bc-4a49-a2cf-6010f4ec829f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Table to profile\n",
    "table_name = \"sc_silver.leads_pbs\"\n",
    "\n",
    "df = spark.table(table_name)\n",
    "total_rows = df.count()\n",
    "\n",
    "if total_rows == 0:\n",
    "    print(f\"{table_name} is empty.\")\n",
    "else:\n",
    "    cols = df.columns\n",
    "\n",
    "    # One pass: compute NULL counts for every column\n",
    "    agg_exprs = [F.sum(F.when(F.col(c).isNull(), 1).otherwise(0)).alias(c) for c in cols]\n",
    "    null_counts_row = df.agg(*agg_exprs)\n",
    "\n",
    "    # Reshape to (column, null_count) and add percentage\n",
    "    stack_expr = \", \".join([f\"'{c}', `{c}`\" for c in cols])\n",
    "    out = (\n",
    "        null_counts_row.selectExpr(f\"stack({len(cols)}, {stack_expr}) as (column, null_count)\")\n",
    "        .withColumn(\"total_rows\", F.lit(total_rows))\n",
    "        .withColumn(\"null_pct\", F.round(F.col(\"null_count\") / F.col(\"total_rows\") * 100, 4))\n",
    "        .orderBy(F.desc(\"null_pct\"), F.desc(\"null_count\"))\n",
    "    )\n",
    "\n",
    "    # Show all rows\n",
    "    out.show(out.count(), truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0ea0436-0012-44bf-9eea-4ad40313176e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Table to profile\n",
    "table_name = \"sc_silver.propostas_realizadas\"\n",
    "\n",
    "df = spark.table(table_name)\n",
    "total_rows = df.count()\n",
    "\n",
    "if total_rows == 0:\n",
    "    print(f\"{table_name} is empty.\")\n",
    "else:\n",
    "    cols = df.columns\n",
    "\n",
    "    # One pass: compute NULL counts for every column\n",
    "    agg_exprs = [F.sum(F.when(F.col(c).isNull(), 1).otherwise(0)).alias(c) for c in cols]\n",
    "    null_counts_row = df.agg(*agg_exprs)\n",
    "\n",
    "    # Reshape to (column, null_count) and add percentage\n",
    "    stack_expr = \", \".join([f\"'{c}', `{c}`\" for c in cols])\n",
    "    out = (\n",
    "        null_counts_row.selectExpr(f\"stack({len(cols)}, {stack_expr}) as (column, null_count)\")\n",
    "        .withColumn(\"total_rows\", F.lit(total_rows))\n",
    "        .withColumn(\"null_pct\", F.round(F.col(\"null_count\") / F.col(\"total_rows\") * 100, 4))\n",
    "        .orderBy(F.desc(\"null_pct\"), F.desc(\"null_count\"))\n",
    "    )\n",
    "\n",
    "    # Show all rows\n",
    "    out.show(out.count(), truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df01964d-583b-4290-b91a-159b6d489258",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Table to profile\n",
    "table_name = \"sc_silver.viaturas\"\n",
    "\n",
    "df = spark.table(table_name)\n",
    "total_rows = df.count()\n",
    "\n",
    "if total_rows == 0:\n",
    "    print(f\"{table_name} is empty.\")\n",
    "else:\n",
    "    cols = df.columns\n",
    "\n",
    "    # One pass: compute NULL counts for every column\n",
    "    agg_exprs = [F.sum(F.when(F.col(c).isNull(), 1).otherwise(0)).alias(c) for c in cols]\n",
    "    null_counts_row = df.agg(*agg_exprs)\n",
    "\n",
    "    # Reshape to (column, null_count) and add percentage\n",
    "    stack_expr = \", \".join([f\"'{c}', `{c}`\" for c in cols])\n",
    "    out = (\n",
    "        null_counts_row.selectExpr(f\"stack({len(cols)}, {stack_expr}) as (column, null_count)\")\n",
    "        .withColumn(\"total_rows\", F.lit(total_rows))\n",
    "        .withColumn(\"null_pct\", F.round(F.col(\"null_count\") / F.col(\"total_rows\") * 100, 4))\n",
    "        .orderBy(F.desc(\"null_pct\"), F.desc(\"null_count\"))\n",
    "    )\n",
    "\n",
    "    # Show all rows\n",
    "    out.show(out.count(), truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9f15b26-8665-48d6-846b-aca482212573",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Table to profile\n",
    "table_name = \"sc_silver.viaturas\"\n",
    "\n",
    "df = spark.table(table_name)\n",
    "total_rows = df.count()\n",
    "\n",
    "if total_rows == 0:\n",
    "    print(f\"{table_name} is empty.\")\n",
    "else:\n",
    "    cols = df.columns\n",
    "\n",
    "    # One pass: compute NULL counts for every column\n",
    "    agg_exprs = [F.sum(F.when(F.col(c).isNull(), 1).otherwise(0)).alias(c) for c in cols]\n",
    "    null_counts_row = df.agg(*agg_exprs)\n",
    "\n",
    "    # Reshape to (column, null_count) and add percentage\n",
    "    stack_expr = \", \".join([f\"'{c}', `{c}`\" for c in cols])\n",
    "    out = (\n",
    "        null_counts_row.selectExpr(f\"stack({len(cols)}, {stack_expr}) as (column, null_count)\")\n",
    "        .withColumn(\"total_rows\", F.lit(total_rows))\n",
    "        .withColumn(\"null_pct\", F.round(F.col(\"null_count\") / F.col(\"total_rows\") * 100, 4))\n",
    "        .orderBy(F.desc(\"null_pct\"), F.desc(\"null_count\"))\n",
    "    )\n",
    "\n",
    "    # Show all rows\n",
    "    out.show(out.count(), truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52c02e00-1a48-432b-aeac-526209af8d43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Table to profile\n",
    "table_name = \"sc_silver.viaturas_demo\"\n",
    "\n",
    "df = spark.table(table_name)\n",
    "total_rows = df.count()\n",
    "\n",
    "if total_rows == 0:\n",
    "    print(f\"{table_name} is empty.\")\n",
    "else:\n",
    "    cols = df.columns\n",
    "\n",
    "    # Compute NULL counts for every column\n",
    "    agg_exprs = [F.sum(F.when(F.col(c).isNull(), 1).otherwise(0)).alias(c) for c in cols]\n",
    "    null_counts_row = df.agg(*agg_exprs)\n",
    "\n",
    "    # Reshape to (column, null_count) and add percentage\n",
    "    stack_expr = \", \".join([f\"'{c}', `{c}`\" for c in cols])\n",
    "    out = (\n",
    "        null_counts_row.selectExpr(f\"stack({len(cols)}, {stack_expr}) as (column, null_count)\")\n",
    "        .withColumn(\"total_rows\", F.lit(total_rows))\n",
    "        .withColumn(\"null_pct\", F.round(F.col(\"null_count\") / F.col(\"total_rows\") * 100, 4))\n",
    "        .orderBy(F.desc(\"null_pct\"), F.desc(\"null_count\"))\n",
    "    )\n",
    "\n",
    "    # Show all rows\n",
    "    out.show(out.count(), truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d4b3dc8-45c5-46cc-81e5-7d9c6f0b123c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SHOW TABLES IN workspace.sc_silver;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d04587f-6064-4821-8dc2-5540689d7309",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.contas_pbs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dc9e9f9-ed17-4dc4-8f5c-f79180d924cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.contas_importador_pbs;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32cca8a9-6260-43d8-92b4-8a8fd158c45c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.campanha_vouchers;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fb02c01-8220-45a8-be8a-7c386491f5eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.campaigns;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8991480c-c1f3-4b1f-9d56-3d22c5adbded",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.bd_rede_hyundai;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09521424-5d3e-4625-abf9-9c55c7a2a33b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.campanhas_tecnicas;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fb058da-d6c6-4c62-9273-851a1fafdf43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.contactos_importador_pbs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd540249-7f6c-41a7-a990-a9172331cfe6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.contactos_pbs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ba78fb0-6a1e-42dd-af4a-2cda9d9b5f48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.contratos_financiamento;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7109e5ef-867e-498c-9a0d-a15023d5d051",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.deals;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0eff3552-d5d6-4d53-80a6-5997f4f1916a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.historico_de_servicos;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "100abd51-30dd-4a46-a4eb-11ed763bdf88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.leads_pbs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c6b7bed-a607-4cea-91bc-f8dbd38660f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.propostas_realizadas;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a6c7e68-0953-4c2f-afb1-5b1a63eca2a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.viaturas;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebdc6a92-1f63-478e-9cca-d60a8e02e827",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "SELECT * FROM sc_silver.viaturas_demo;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0721f701-e742-4076-9309-201a6dab599a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 1) See each duplicate pair and how many times it appears\n",
    "SELECT id, created_time, COUNT(*) AS cnt\n",
    "FROM sc_silver.leads_pbs\n",
    "GROUP BY id, created_time\n",
    "HAVING COUNT(*) > 1\n",
    "ORDER BY cnt DESC;\n",
    "\n",
    "-- 2) Count total duplicate rows (excluding first occurrence in each group)\n",
    "WITH grouped AS (\n",
    "    SELECT id, created_time, COUNT(*) AS cnt\n",
    "    FROM sc_silver.leads_pbs\n",
    "    GROUP BY id, created_time\n",
    ")\n",
    "SELECT SUM(cnt - 1) AS total_duplicate_rows\n",
    "FROM grouped\n",
    "WHERE cnt > 1;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6086950-5896-4815-8da5-47d19cd4861b",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"id\":221,\"_fivetran_id\":190},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755282394313}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM (\n",
    "    SELECT *,\n",
    "           COUNT(*) OVER (PARTITION BY id, created_time) AS cnt\n",
    "    FROM sc_silver.leads_pbs\n",
    ") t\n",
    "WHERE cnt > 1\n",
    "ORDER BY id, created_time;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6407020-75a5-4b77-8332-00a1f9499f38",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"id\":193,\"lead_owner\":251,\"_fivetran_id\":168},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755291548592}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT a.*\n",
    "FROM sc_silver.leads_pbs a\n",
    "JOIN (\n",
    "  SELECT _fivetran_id, ROW_NUMBER() OVER (PARTITION BY id, created_time ORDER BY _fivetran_id) rn\n",
    "  FROM sc_silver.leads_pbs\n",
    ") b\n",
    "ON a._fivetran_id = b._fivetran_id\n",
    "WHERE b.rn > 1\n",
    "ORDER BY a.id, a.created_time;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "562b45af-07d9-499e-8a15-6be0de27052e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 1) See each duplicate pair and how many times it appears\n",
    "SELECT id, created_time, COUNT(*) AS cnt\n",
    "FROM sc_silver.leads_pbs\n",
    "GROUP BY id, created_time\n",
    "HAVING COUNT(*) > 1\n",
    "ORDER BY cnt DESC;\n",
    "\n",
    "-- 2) Count total duplicate rows (excluding first occurrence in each group)\n",
    "WITH grouped AS (\n",
    "    SELECT id, created_time, COUNT(*) AS cnt\n",
    "    FROM sc_silver.leads_pbs\n",
    "    GROUP BY id, created_time\n",
    ")\n",
    "SELECT SUM(cnt - 1) AS total_duplicate_rows\n",
    "FROM grouped\n",
    "WHERE cnt > 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "326625fd-f464-4339-9559-f8faa554eda0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM (\n",
    "    SELECT *,\n",
    "           COUNT(*) OVER (PARTITION BY id, created_time) AS cnt\n",
    "    FROM sc_silver.leads_pbs\n",
    ") t\n",
    "WHERE cnt > 1\n",
    "ORDER BY id, created_time;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54040b50-db6e-4e59-bcaf-4591c9abe5d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 1) Duplicate (id, data_criacao_da_lead) pairs and their counts\n",
    "SELECT id, data_criacao_da_lead, COUNT(*) AS cnt\n",
    "FROM sc_silver.Contactos_PBS\n",
    "GROUP BY id, data_criacao_da_lead\n",
    "HAVING COUNT(*) > 1\n",
    "ORDER BY cnt DESC;\n",
    "\n",
    "-- 2) Total number of duplicate rows (excluding the first in each pair)\n",
    "WITH grouped AS (\n",
    "  SELECT id, data_criacao_da_lead, COUNT(*) AS cnt\n",
    "  FROM sc_silver.Contactos_PBS\n",
    "  GROUP BY id, data_criacao_da_lead\n",
    ")\n",
    "SELECT COALESCE(SUM(cnt - 1), 0) AS total_duplicate_rows\n",
    "FROM grouped\n",
    "WHERE cnt > 1;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eaa677f5-abc2-4cdf-ae27-ef3c4f6f5f9b",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"id\":214},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755291041575}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM (\n",
    "  SELECT *,\n",
    "         COUNT(*) OVER (PARTITION BY id, created_time) AS cnt\n",
    "  FROM sc_silver.contactos_pbs\n",
    ") t\n",
    "WHERE cnt > 1\n",
    "ORDER BY id, created_time;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4f05dc7-f23a-4aa0-81bb-55cb3c61d402",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 1) Duplicate (id, created_time) pairs and their counts\n",
    "SELECT id, created_time, COUNT(*) AS cnt\n",
    "FROM sc_silver.contactos_pbs\n",
    "GROUP BY id, created_time\n",
    "HAVING COUNT(*) > 1\n",
    "ORDER BY cnt DESC, id, created_time;\n",
    "\n",
    "-- 2) Total duplicate rows (excluding the first in each pair)\n",
    "WITH grouped AS (\n",
    "  SELECT id, created_time, COUNT(*) AS cnt\n",
    "  FROM sc_silver.contactos_pbs\n",
    "  GROUP BY id, created_time\n",
    ")\n",
    "SELECT COALESCE(SUM(cnt - 1), 0) AS total_duplicate_rows\n",
    "FROM grouped\n",
    "WHERE cnt > 1;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17ef3677-c926-4273-943c-3bfbaa63d6ff",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"created_time\":271,\"id\":223,\"cnt\":142,\"proposta_ids\":286},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755292472689}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT\n",
    "  id,\n",
    "  created_time,\n",
    "  COUNT(*) AS cnt,\n",
    "  COLLECT_SET(id_proposta_realizada) AS proposta_ids  -- use COLLECT_LIST if you want repeats\n",
    "FROM sc_silver.propostas_realizadas\n",
    "GROUP BY id, created_time\n",
    "HAVING COUNT(*) > 1\n",
    "ORDER BY cnt DESC, id, created_time;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a280220c-5ae0-4d4e-9dc3-90eef05c88b7",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"created_time\":327,\"id\":244},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755292673673}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT\n",
    "  id,\n",
    "  created_time,\n",
    "  id_proposta_realizada,\n",
    "  subject,\n",
    "  proposta_realizada_owner,\n",
    "  proposta_realizada_owner_name,\n",
    "  cnt\n",
    "FROM (\n",
    "  SELECT *,\n",
    "         COUNT(*) OVER (PARTITION BY id, created_time) AS cnt\n",
    "  FROM sc_silver.propostas_realizadas\n",
    ") t\n",
    "WHERE cnt > 1\n",
    "ORDER BY id, created_time, id_proposta_realizada;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9072344b-43dc-4ad5-96f7-625e7d8d2dc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM (\n",
    "  SELECT *,\n",
    "         COUNT(*) OVER (PARTITION BY id, created_time) AS cnt\n",
    "  FROM sc_silver.contactos_pbs\n",
    ") t\n",
    "WHERE cnt > 1\n",
    "ORDER BY id, created_time;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98a154f3-9772-4c79-8189-478d4d023be6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Show the actual rows that belong to duplicated (id, created_time) pairs\n",
    "SELECT *\n",
    "FROM (\n",
    "  SELECT d.*,\n",
    "         COUNT(*) OVER (PARTITION BY id, created_time) AS cnt\n",
    "  FROM sc_silver.deals d\n",
    ") t\n",
    "WHERE cnt > 1\n",
    "ORDER BY id, created_time;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd549c64-0ce2-4583-9529-98bee1d74c3a",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"id\":213},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755293256163}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT id, created_time, COUNT(*) AS cnt\n",
    "FROM sc_silver.deals\n",
    "GROUP BY id, created_time\n",
    "HAVING COUNT(*) > 1\n",
    "ORDER BY cnt DESC, id, created_time;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c072fad3-8330-4a63-be9e-5583110d73ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- (Optional) Preview rows that would be deleted\n",
    "SELECT a.*\n",
    "FROM sc_silver.deals a\n",
    "JOIN (\n",
    "  SELECT _fivetran_id,\n",
    "         ROW_NUMBER() OVER (\n",
    "           PARTITION BY id, created_time\n",
    "           ORDER BY _fivetran_id          -- pick your preferred tiebreaker\n",
    "         ) AS rn\n",
    "  FROM sc_silver.deals\n",
    ") r\n",
    "ON a._fivetran_id = r._fivetran_id\n",
    "WHERE r.rn > 1\n",
    "ORDER BY a.id, a.created_time, a._fivetran_id;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a559b41-35f9-4fbc-8518-d8eea97717e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT id, created_time, COUNT(*) AS cnt\n",
    "FROM sc_silver.deals\n",
    "GROUP BY id, created_time\n",
    "HAVING COUNT(*) > 1\n",
    "ORDER BY cnt DESC, id, created_time;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de4ff887-f784-46db-8fb7-6f4786a9fedc",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"id\":216},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755294794727}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- sc_silver.contas_pbs\n",
    "SELECT *\n",
    "FROM (\n",
    "  SELECT t.*,\n",
    "         COUNT(*) OVER (PARTITION BY id, created_time) AS cnt\n",
    "  FROM sc_silver.contas_pbs t\n",
    ") t\n",
    "WHERE cnt > 1\n",
    "ORDER BY id, created_time;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c722822-f5a6-494d-b5ca-8bf4fe24d1e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- sc_silver.contas_importador_pbs\n",
    "SELECT *\n",
    "FROM (\n",
    "  SELECT t.*,\n",
    "         COUNT(*) OVER (PARTITION BY id, created_time) AS cnt\n",
    "  FROM sc_silver.contas_importador_pbs t\n",
    ") t\n",
    "WHERE cnt > 1\n",
    "ORDER BY id, created_time;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab91840b-467d-4a05-b0b5-f2d0ce6a0976",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- sc_silver.campanha_vouchers\n",
    "SELECT *\n",
    "FROM (\n",
    "  SELECT t.*,\n",
    "         COUNT(*) OVER (PARTITION BY id, created_time) AS cnt\n",
    "  FROM sc_silver.campanha_vouchers t\n",
    ") t\n",
    "WHERE cnt > 1\n",
    "ORDER BY id, created_time;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "409317cf-8f86-4472-859f-c68ae11baef2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- sc_silver.bd_rede_hyundai\n",
    "SELECT *\n",
    "FROM (\n",
    "  SELECT t.*,\n",
    "         COUNT(*) OVER (PARTITION BY id, created_time) AS cnt\n",
    "  FROM sc_silver.bd_rede_hyundai t\n",
    ") t\n",
    "WHERE cnt > 1\n",
    "ORDER BY id, created_time;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26afa282-0bd2-43ce-8ad1-ada4675df761",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- sc_silver.campanhas_tecnicas\n",
    "SELECT *\n",
    "FROM (\n",
    "  SELECT t.*,\n",
    "         COUNT(*) OVER (PARTITION BY id, created_time) AS cnt\n",
    "  FROM sc_silver.campanhas_tecnicas t\n",
    ") t\n",
    "WHERE cnt > 1\n",
    "ORDER BY id, created_time;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b4e5011-13dc-47ab-b16b-5ccc43c5e70b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- sc_silver.contactos_importador_pbs\n",
    "SELECT *\n",
    "FROM (\n",
    "  SELECT t.*,\n",
    "         COUNT(*) OVER (PARTITION BY id, created_time) AS cnt\n",
    "  FROM sc_silver.contactos_importador_pbs t\n",
    ") t\n",
    "WHERE cnt > 1\n",
    "ORDER BY id, created_time;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "686f44a0-4ecd-45cf-8195-b6e72244b970",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- sc_silver.contratos_financiamento\n",
    "SELECT *\n",
    "FROM (\n",
    "  SELECT t.*,\n",
    "         COUNT(*) OVER (PARTITION BY id, created_time) AS cnt\n",
    "  FROM sc_silver.contratos_financiamento t\n",
    ") t\n",
    "WHERE cnt > 1\n",
    "ORDER BY id, created_time;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "caeae908-e11c-4684-8c84-56b23ea61fdf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- sc_silver.historico_de_servicos\n",
    "SELECT *\n",
    "FROM (\n",
    "  SELECT t.*,\n",
    "         COUNT(*) OVER (PARTITION BY id, created_time) AS cnt\n",
    "  FROM sc_silver.historico_de_servicos t\n",
    ") t\n",
    "WHERE cnt > 1\n",
    "ORDER BY id, created_time;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "204bf95b-d78d-4d7b-9c08-1a8b516ff701",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- sc_silver.viaturas\n",
    "SELECT *\n",
    "FROM (\n",
    "  SELECT t.*,\n",
    "         COUNT(*) OVER (PARTITION BY id, created_time) AS cnt\n",
    "  FROM sc_silver.viaturas t\n",
    ") t\n",
    "WHERE cnt > 1\n",
    "ORDER BY id, created_time;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b491ada-a988-48ba-b653-b6e2489159af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- sc_silver.viaturas_demo\n",
    "SELECT *\n",
    "FROM (\n",
    "  SELECT t.*,\n",
    "         COUNT(*) OVER (PARTITION BY id, created_time) AS cnt\n",
    "  FROM sc_silver.viaturas_demo t\n",
    ") t\n",
    "WHERE cnt > 1\n",
    "ORDER BY id, created_time;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f259da9a-e54e-4f70-84d1-c3f7c679014a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks: run as a Python cell\n",
    "from pyspark.sql import functions as F, types as T\n",
    "\n",
    "TABLES = [\n",
    "    \"sc_silver.bd_rede_hyundai\",\n",
    "    \"sc_silver.campaigns\",\n",
    "    \"sc_silver.campanha_vouchers\",\n",
    "    \"sc_silver.campanhas_tecnicas\",\n",
    "    \"sc_silver.contactos_importador_pbs\",\n",
    "    \"sc_silver.contactos_pbs\",\n",
    "    \"sc_silver.contas_importador_pbs\",\n",
    "    \"sc_silver.contas_pbs\",\n",
    "    \"sc_silver.contratos_financiamento\",\n",
    "    \"sc_silver.deals\",\n",
    "    \"sc_silver.historico_de_servicos\",\n",
    "    \"sc_silver.leads_pbs\",\n",
    "    \"sc_silver.propostas_realizadas\",\n",
    "    \"sc_silver.viaturas\",\n",
    "    \"sc_silver.viaturas_demo\",\n",
    "]\n",
    "\n",
    "def preserve_case(colname: str) -> bool:\n",
    "    \"\"\"\n",
    "    Columns to NOT proper-case (keep original case, only trim):\n",
    "    IDs, emails, URLs, VIN/IBAN, geo codes, date/time-like, etc.\n",
    "    \"\"\"\n",
    "    c = colname.lower()\n",
    "    if c == \"id\" or c.endswith(\"_id\") or c.endswith(\"id\"):\n",
    "        return True\n",
    "    sensitive_terms = [\n",
    "        \"email\", \"mail\", \"url\", \"http\", \"https\",\n",
    "        \"vin\", \"iban\", \"bic\", \"swift\", \"uuid\", \"guid\", \"imei\", \"ip\", \"mac\",\n",
    "        \"nif\", \"nipc\", \"niss\", \"vat\",\n",
    "        \"postal\", \"codigo_postal\", \"zip\", \"cep\",\n",
    "        \"matricula\", \"placa\", \"chassis\", \"plate\",\n",
    "        \"lat\", \"lng\", \"lon\", \"latitude\", \"longitude\",\n",
    "    ]\n",
    "    if any(term in c for term in sensitive_terms):\n",
    "        return True\n",
    "    # date/time-like names\n",
    "    if \"date\" in c or \"data\" in c or \"time\" in c or \"timestamp\" in c:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clean_string_col(name: str):\n",
    "    col = F.col(name)\n",
    "    # Trim ONLY ends; DO NOT normalize internal spaces or remove control chars; DO NOT map \"\" -> NULL\n",
    "    col = F.trim(col)\n",
    "    # Proper-case (per word) unless column should preserve case\n",
    "    if not preserve_case(name):\n",
    "        col = F.initcap(F.lower(col))  # e.g., \"JOÃO DA SILVA\" -> \"JoÃ£o Da Silva\"\n",
    "    return col.alias(name)\n",
    "\n",
    "def clean_df(df):\n",
    "    out = []\n",
    "    for f in df.schema.fields:\n",
    "        if isinstance(f.dataType, T.StringType):\n",
    "            out.append(clean_string_col(f.name))\n",
    "        else:\n",
    "            # non-string columns unchanged\n",
    "            out.append(F.col(f.name))\n",
    "    return df.select(*out)\n",
    "\n",
    "for full_name in TABLES:\n",
    "    df = spark.table(full_name)\n",
    "    df_clean = clean_df(df)\n",
    "    # Overwrite original table in place (Delta)\n",
    "    df_clean.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(full_name)\n",
    "    print(f\"Overwrote: {full_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3ffde07-58ab-473e-b20c-f7c596754c19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "SELECT * FROM sc_silver.bd_rede_hyundai;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c9777a7-74a4-4f47-b6d4-ba1728ee2bc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, MapType, StructType\n",
    "\n",
    "tbl = \"sc_silver.bd_rede_hyundai\"\n",
    "TOP_N = 100        # change or remove the .limit() below\n",
    "INCLUDE_NULLS = False\n",
    "\n",
    "df = spark.table(tbl)\n",
    "\n",
    "# Skip complex types that can't be grouped directly\n",
    "simple_cols = [f.name for f in df.schema.fields\n",
    "               if not isinstance(f.dataType, (ArrayType, MapType, StructType))]\n",
    "\n",
    "for c in simple_cols:\n",
    "    q = df.select(c)\n",
    "    if not INCLUDE_NULLS:\n",
    "        q = q.where(F.col(c).isNotNull())\n",
    "    print(f\"=== {c} ===\")\n",
    "    display(\n",
    "        q.groupBy(F.col(c)).count()\n",
    "         .orderBy(F.desc(\"count\"))\n",
    "         .limit(TOP_N)  # remove to see all\n",
    "         .withColumnRenamed(c, \"value\")\n",
    "         .select(\"value\", \"count\")  # no need to show the column name in the result\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a4e29f3-3956-4bbd-9d8b-5ae9c3d4e926",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.campaigns;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "baa43fb1-4b8c-45db-aaa6-3d146492f7e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.campanha_vouchers;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a92f5d8-47c6-48c4-b737-9ca9eeb23a0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.campanhas_tecnicas;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2370e19f-0553-4c51-bb46-85f2221de466",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.contactos_importador_pbs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "960fec02-4009-4ecb-acf7-939d11ad6772",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, MapType, StructType\n",
    "\n",
    "tbl = \"sc_silver.contactos_importador_pbs\"\n",
    "TOP_N = 100        # change or remove the .limit() below\n",
    "INCLUDE_NULLS = False\n",
    "\n",
    "df = spark.table(tbl)\n",
    "\n",
    "# Skip complex types that can't be grouped directly\n",
    "simple_cols = [f.name for f in df.schema.fields\n",
    "               if not isinstance(f.dataType, (ArrayType, MapType, StructType))]\n",
    "\n",
    "for c in simple_cols:\n",
    "    q = df.select(c)\n",
    "    if not INCLUDE_NULLS:\n",
    "        q = q.where(F.col(c).isNotNull())\n",
    "    print(f\"=== {tbl}.{c} ===\")\n",
    "    display(\n",
    "        q.groupBy(F.col(c)).count()\n",
    "         .orderBy(F.desc(\"count\"))\n",
    "         .limit(TOP_N)                     # remove to see all values\n",
    "         .withColumnRenamed(c, \"value\")\n",
    "         .select(\"value\", \"count\")         # result has just the distinct values + counts\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74eb5370-33fc-4d2b-af08-7a8284215ad9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "WITH cleaned AS (\n",
    "  SELECT\n",
    "    tipo_viatura,\n",
    "    -- base text before the first [, else the first quoted item inside [...]\n",
    "    trim(\n",
    "      coalesce(\n",
    "        regexp_extract(tipo_viatura, '^[^\\\\[]+', 0),   -- e.g. \"Novos[\"Usados\"]\" -> \"Novos\"\n",
    "        regexp_extract(tipo_viatura, '\"([^\"]+)\"', 1)   -- e.g. '[\"Novos\"]' -> \"Novos\"\n",
    "      )\n",
    "    ) AS base\n",
    "  FROM sc_silver.contactos_importador_pbs\n",
    ")\n",
    "SELECT\n",
    "  CASE\n",
    "    WHEN lower(base) rlike '^nov'              THEN 'Novos'\n",
    "    WHEN lower(base) rlike '^(usad|semi)'      THEN 'Usados'\n",
    "    WHEN lower(base) rlike '^emp'              THEN 'Empresas'\n",
    "    WHEN base = '' OR base IS NULL             THEN NULL\n",
    "    ELSE initcap(base)\n",
    "  END AS tipo_viatura_clean,\n",
    "  count(*) AS cnt\n",
    "FROM cleaned\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25323c1c-3687-40dd-b6b0-c9aa9b9f388e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT tipo_viatura, count(*) AS cnt\n",
    "FROM sc_silver.contactos_importador_pbs\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc73005d-4757-4a57-91fc-030d5fd61409",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT tipo_viatura, COUNT(*) AS cnt\n",
    "FROM sc_silver.contactos_importador_pbs\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "808c3741-5496-42df-a898-1bc5bd566b6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT tipo_viatura, COUNT(*) AS cnt\n",
    "FROM sc_silver.contactos_importador_pbs\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec839cb9-501e-4dde-ad3a-c3841f541a5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "WITH tok AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    -- keep only digits & commas, then split; drop empties; dedupe\n",
    "    array_distinct(\n",
    "      filter(\n",
    "        split(regexp_replace(coalesce(id_contactos,''), '[^0-9,]', ''), ','),\n",
    "        x -> x <> ''\n",
    "      )\n",
    "    ) AS id_list\n",
    "  FROM sc_silver.contactos_importador_pbs\n",
    ")\n",
    "SELECT size(id_list) AS n_ids, count(*) AS cnt\n",
    "FROM tok\n",
    "GROUP BY 1 ORDER BY 1 DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d584b70e-7387-4507-8d0e-922ff942529b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.contactos_importador_pbs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e62cc31-9802-4fda-b469-c909af72ec15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, MapType, StructType\n",
    "\n",
    "tbl = \"sc_silver.contactos_pbs\"\n",
    "TOP_N = 100        # change or remove the .limit() below\n",
    "INCLUDE_NULLS = False\n",
    "\n",
    "df = spark.table(tbl)\n",
    "\n",
    "# Skip complex types that can't be grouped directly\n",
    "simple_cols = [f.name for f in df.schema.fields\n",
    "               if not isinstance(f.dataType, (ArrayType, MapType, StructType))]\n",
    "\n",
    "for c in simple_cols:\n",
    "    q = df.select(c)\n",
    "    if not INCLUDE_NULLS:\n",
    "        q = q.where(F.col(c).isNotNull())\n",
    "    print(f\"=== {tbl}.{c} ===\")\n",
    "    display(\n",
    "        q.groupBy(F.col(c)).count()\n",
    "         .orderBy(F.desc(\"count\"))\n",
    "         .limit(TOP_N)                     # remove to see all values\n",
    "         .withColumnRenamed(c, \"value\")\n",
    "         .select(\"value\", \"count\")         # result has just the distinct values + counts\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc4f448c-13cb-4d24-a402-a425fb111ce3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, MapType, StructType\n",
    "\n",
    "tbl = \"sc_silver.contas_importador_pbs\"\n",
    "TOP_N = 100        # adjust or remove .limit() below\n",
    "INCLUDE_NULLS = False\n",
    "\n",
    "df = spark.table(tbl)\n",
    "\n",
    "# Only columns we can group on directly\n",
    "simple_cols = [f.name for f in df.schema.fields\n",
    "               if not isinstance(f.dataType, (ArrayType, MapType, StructType))]\n",
    "\n",
    "for c in simple_cols:\n",
    "    q = df.select(c)\n",
    "    if not INCLUDE_NULLS:\n",
    "        q = q.where(F.col(c).isNotNull())\n",
    "    print(f\"=== {tbl}.{c} ===\")\n",
    "    display(\n",
    "        q.groupBy(F.col(c)).count()\n",
    "         .orderBy(F.desc(\"count\"))\n",
    "         .limit(TOP_N)\n",
    "         .withColumnRenamed(c, \"value\")\n",
    "         .select(\"value\", \"count\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a5d383e-7f59-4aa0-9c43-5479517f7194",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, MapType, StructType\n",
    "\n",
    "tbl = \"sc_silver.contas_pbs\"\n",
    "TOP_N = 100        # adjust or remove .limit() below\n",
    "INCLUDE_NULLS = False\n",
    "\n",
    "df = spark.table(tbl)\n",
    "\n",
    "# Only columns we can group on directly\n",
    "simple_cols = [f.name for f in df.schema.fields\n",
    "               if not isinstance(f.dataType, (ArrayType, MapType, StructType))]\n",
    "\n",
    "for c in simple_cols:\n",
    "    q = df.select(c)\n",
    "    if not INCLUDE_NULLS:\n",
    "        q = q.where(F.col(c).isNotNull())\n",
    "    print(f\"=== {tbl}.{c} ===\")\n",
    "    display(\n",
    "        q.groupBy(F.col(c)).count()\n",
    "         .orderBy(F.desc(\"count\"))\n",
    "         .limit(TOP_N)\n",
    "         .withColumnRenamed(c, \"value\")\n",
    "         .select(\"value\", \"count\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01c57805-9351-48cb-a8e6-a83177fb384d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, MapType, StructType\n",
    "\n",
    "tbl = \"sc_silver.contratos_financiamento\"\n",
    "TOP_N = 100        # adjust or remove .limit() below\n",
    "INCLUDE_NULLS = False\n",
    "\n",
    "df = spark.table(tbl)\n",
    "\n",
    "# Only columns we can group on directly\n",
    "simple_cols = [f.name for f in df.schema.fields\n",
    "               if not isinstance(f.dataType, (ArrayType, MapType, StructType))]\n",
    "\n",
    "for c in simple_cols:\n",
    "    q = df.select(c)\n",
    "    if not INCLUDE_NULLS:\n",
    "        q = q.where(F.col(c).isNotNull())\n",
    "    print(f\"=== {tbl}.{c} ===\")\n",
    "    display(\n",
    "        q.groupBy(F.col(c)).count()\n",
    "         .orderBy(F.desc(\"count\"))\n",
    "         .limit(TOP_N)\n",
    "         .withColumnRenamed(c, \"value\")\n",
    "         .select(\"value\", \"count\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bfe8808-b542-4a73-997f-1704c607de06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sc_silver.contratos_financiamento;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cd992e7-b273-4ff8-8711-fdea802e5316",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, MapType, StructType\n",
    "\n",
    "tbl = \"sc_silver.deals\"\n",
    "TOP_N = 100        # adjust or remove .limit() below\n",
    "INCLUDE_NULLS = False\n",
    "\n",
    "df = spark.table(tbl)\n",
    "\n",
    "# Only columns we can group on directly\n",
    "simple_cols = [f.name for f in df.schema.fields\n",
    "               if not isinstance(f.dataType, (ArrayType, MapType, StructType))]\n",
    "\n",
    "for c in simple_cols:\n",
    "    q = df.select(c)\n",
    "    if not INCLUDE_NULLS:\n",
    "        q = q.where(F.col(c).isNotNull())\n",
    "    print(f\"=== {tbl}.{c} ===\")\n",
    "    display(\n",
    "        q.groupBy(F.col(c)).count()\n",
    "         .orderBy(F.desc(\"count\"))\n",
    "         .limit(TOP_N)\n",
    "         .withColumnRenamed(c, \"value\")\n",
    "         .select(\"value\", \"count\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ee0711a-3f70-4ecb-885d-14d576da6abc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Preview the normalization (no write)\n",
    "WITH parsed AS (\n",
    "  SELECT *,\n",
    "    filter(\n",
    "      array_distinct(array(\n",
    "        CASE WHEN regexp_like(categoria_negocio, '(?i)nov')                      THEN 'Novos'    END,\n",
    "        CASE WHEN regexp_like(categoria_negocio, '(?i)usad')                     THEN 'Usados'   END,\n",
    "        CASE WHEN regexp_like(categoria_negocio, '(?i)demo')                     THEN 'Demo'     END,\n",
    "        CASE WHEN regexp_like(categoria_negocio, '(?i)servi(Ã§|c)o?s?')           THEN 'Servicos' END\n",
    "      )),\n",
    "      x -> x IS NOT NULL\n",
    "    ) AS cats\n",
    "  FROM sc_silver.deals\n",
    ")\n",
    "SELECT nullif(array_join(array_sort(cats), ';'), '') AS categoria_norm, count(*) AS cnt\n",
    "FROM parsed\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9348ee43-9cc8-4041-bc02-1b4a11623df4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "WITH mapped AS (\n",
    "  SELECT\n",
    "    CASE\n",
    "      WHEN regexp_like(categoria_negocio, '(?i)demo')                     THEN 'Demo'\n",
    "      WHEN regexp_like(categoria_negocio, '(?i)nov')                      THEN 'Novos'\n",
    "      WHEN regexp_like(categoria_negocio, '(?i)usad')                     THEN 'Usados'\n",
    "      WHEN regexp_like(categoria_negocio, '(?i)servi(Ã§|c)o?s?')           THEN NULL\n",
    "      ELSE NULL\n",
    "    END AS categoria_final\n",
    "  FROM sc_silver.deals\n",
    ")\n",
    "SELECT categoria_final, COUNT(*) cnt\n",
    "FROM mapped\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "309cccde-08f3-47e2-806c-5cbbdb55f4c5",
     "showTitle": false,
     "tableResultSettingsMap": {
      "18": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"value\":414},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755366871287}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 18
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, MapType, StructType\n",
    "\n",
    "tbl = \"sc_silver.historico_de_servicos\"\n",
    "TOP_N = 100        # adjust or remove .limit() below\n",
    "INCLUDE_NULLS = False\n",
    "\n",
    "df = spark.table(tbl)\n",
    "\n",
    "# Only columns we can group on directly\n",
    "simple_cols = [f.name for f in df.schema.fields\n",
    "               if not isinstance(f.dataType, (ArrayType, MapType, StructType))]\n",
    "\n",
    "for c in simple_cols:\n",
    "    q = df.select(c)\n",
    "    if not INCLUDE_NULLS:\n",
    "        q = q.where(F.col(c).isNotNull())\n",
    "    print(f\"=== {tbl}.{c} ===\")\n",
    "    display(\n",
    "        q.groupBy(F.col(c)).count()\n",
    "         .orderBy(F.desc(\"count\"))\n",
    "         .limit(TOP_N)\n",
    "         .withColumnRenamed(c, \"value\")\n",
    "         .select(\"value\", \"count\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03855563-bdb9-422d-bf79-0528795869da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "WITH src AS (\n",
    "  SELECT\n",
    "    tipo_de_servico AS raw,\n",
    "    regexp_replace(lower(coalesce(tipo_de_servico,'')), '[^a-z]', '') AS s\n",
    "  FROM sc_silver.historico_de_servicos\n",
    ")\n",
    "SELECT\n",
    "  CASE\n",
    "    WHEN s RLIKE 'manut|rev|serv'                 THEN 'ManutenÃ§Ã£o'\n",
    "    WHEN s RLIKE 'rep|arranj|cons'                THEN 'ReparaÃ§Ã£o'\n",
    "    WHEN s RLIKE 'mec|el|motor|electricidade'                 THEN 'MecÃ¢nica'\n",
    "    WHEN s RLIKE 'chapa|chapar|chapari'                THEN 'Chapa'\n",
    "    WHEN s RLIKE 'pint'                              THEN 'Pintura'\n",
    "    WHEN s RLIKE 'colis'                               THEN 'ColisÃ£o'\n",
    "ELSE 'ManutenÃ§Ã£o'\n",
    "  END AS categoria_norm,\n",
    "  COUNT(*) AS cnt\n",
    "FROM src\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d935ee3-fc12-42fa-b635-308ff58afee1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT tipo_de_servico, COUNT(*) AS cnt\n",
    "FROM sc_silver.historico_de_servicos\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d31a615b-18da-4ac2-a37f-1b03b0dc7192",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, MapType, StructType\n",
    "\n",
    "tbl = \"sc_silver.leads_pbs\"\n",
    "TOP_N = 100        # adjust or remove .limit() below\n",
    "INCLUDE_NULLS = False\n",
    "\n",
    "df = spark.table(tbl)\n",
    "\n",
    "# Only columns we can group on directly\n",
    "simple_cols = [f.name for f in df.schema.fields\n",
    "               if not isinstance(f.dataType, (ArrayType, MapType, StructType))]\n",
    "\n",
    "for c in simple_cols:\n",
    "    q = df.select(c)\n",
    "    if not INCLUDE_NULLS:\n",
    "        q = q.where(F.col(c).isNotNull())\n",
    "    print(f\"=== {tbl}.{c} ===\")\n",
    "    display(\n",
    "        q.groupBy(F.col(c)).count()\n",
    "         .orderBy(F.desc(\"count\"))\n",
    "         .limit(TOP_N)\n",
    "         .withColumnRenamed(c, \"value\")\n",
    "         .select(\"value\", \"count\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cb6ff37-d6c7-4192-b52d-13ad2d16f473",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT lead_status_2, COUNT(*) AS cnt\n",
    "FROM sc_silver.leads_pbs\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74fed885-9b25-49ce-bc69-a73a2f9b5fda",
     "showTitle": false,
     "tableResultSettingsMap": {
      "71": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"value\":194},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755369888418}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 71
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, MapType, StructType\n",
    "\n",
    "tbl = \"sc_silver.propostas_realizadas\"\n",
    "TOP_N = 100        # adjust or remove .limit() below\n",
    "INCLUDE_NULLS = False\n",
    "\n",
    "df = spark.table(tbl)\n",
    "\n",
    "# Only columns we can group on directly\n",
    "simple_cols = [f.name for f in df.schema.fields\n",
    "               if not isinstance(f.dataType, (ArrayType, MapType, StructType))]\n",
    "\n",
    "for c in simple_cols:\n",
    "    q = df.select(c)\n",
    "    if not INCLUDE_NULLS:\n",
    "        q = q.where(F.col(c).isNotNull())\n",
    "    print(f\"=== {tbl}.{c} ===\")\n",
    "    display(\n",
    "        q.groupBy(F.col(c)).count()\n",
    "         .orderBy(F.desc(\"count\"))\n",
    "         .limit(TOP_N)\n",
    "         .withColumnRenamed(c, \"value\")\n",
    "         .select(\"value\", \"count\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63190f50-8a83-4885-be61-18f56c5e7ba2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT categoria_proposta, COUNT(*) cnt\n",
    "FROM sc_silver.propostas_realizadas\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b539ee7-e4bd-4751-ac5a-636744488958",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT combustivel, COUNT(*) AS cnt\n",
    "FROM sc_silver.propostas_realizadas\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f0ae7a4-c745-485b-8538-d91c514a94bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT tipo_cliente, COUNT(*) AS cnt\n",
    "FROM sc_silver.propostas_realizadas\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eaefa2bb-92bd-4043-bd3a-ecec72a4f282",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "WITH src AS (\n",
    "  SELECT\n",
    "    descricao_pintura AS raw,\n",
    "    -- normalize accents + strip non-letters\n",
    "    regexp_replace(\n",
    "      lower(translate(coalesce(descricao_pintura,''),\n",
    "        'Ã¡Ã Ã¢Ã£Ã¤Ã©Ã¨ÃªÃ«Ã­Ã¬Ã®Ã¯Ã³Ã²Ã´ÃµÃ¶ÃºÃ¹Ã»Ã¼Ã§ÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃ',\n",
    "        'aaaaaeeeeiiiiooooouuuucAAAAAEEEEIIIIOOOOOUUUUC'\n",
    "      )),\n",
    "      '[^a-z]', ''\n",
    "    ) AS s\n",
    "  FROM sc_silver.propostas_realizadas\n",
    ")\n",
    "SELECT\n",
    "  CASE\n",
    "    WHEN s RLIKE 'metaliz.*especial' THEN 'Metalizada Especial'\n",
    "    WHEN s RLIKE 'metaliz|^metal$'   THEN 'Metalizada'        -- includes \"Metal\"\n",
    "    WHEN s RLIKE 'solid'             THEN 'SÃ³lida'\n",
    "    ELSE NULL\n",
    "  END AS pintura_norm,\n",
    "  COUNT(*) AS cnt\n",
    "FROM src\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eca7f0d7-d4a4-4e01-a4c6-f2fa68d319ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT descricao_pintura, COUNT(*) AS cnt\n",
    "FROM sc_silver.propostas_realizadas\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c06a3a2-3cba-4a67-94ad-472b205275d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT estado_do_pedido, COUNT(*) AS cnt\n",
    "FROM sc_silver.propostas_realizadas\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a395b43-1f87-4d05-aeca-480565afcb49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT estado_do_pedido, COUNT(*) AS cnt\n",
    "FROM sc_silver.propostas_realizadas\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54600481-6c61-4af3-945e-e31c1db876aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, MapType, StructType\n",
    "\n",
    "tbl = \"sc_silver.viaturas\"\n",
    "TOP_N = 100        # adjust or remove .limit() below\n",
    "INCLUDE_NULLS = False\n",
    "\n",
    "df = spark.table(tbl)\n",
    "\n",
    "# Only columns we can group on directly\n",
    "simple_cols = [f.name for f in df.schema.fields\n",
    "               if not isinstance(f.dataType, (ArrayType, MapType, StructType))]\n",
    "\n",
    "for c in simple_cols:\n",
    "    q = df.select(c)\n",
    "    if not INCLUDE_NULLS:\n",
    "        q = q.where(F.col(c).isNotNull())\n",
    "    print(f\"=== {tbl}.{c} ===\")\n",
    "    display(\n",
    "        q.groupBy(F.col(c)).count()\n",
    "         .orderBy(F.desc(\"count\"))\n",
    "         .limit(TOP_N)\n",
    "         .withColumnRenamed(c, \"value\")\n",
    "         .select(\"value\", \"count\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58eaa44d-5301-4d60-9c13-89217c40b89d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "WITH src AS (\n",
    "  SELECT\n",
    "    combustivel AS raw,\n",
    "    -- normaliza: baixa, remove acentos, tira nÃ£o-letras\n",
    "    regexp_replace(\n",
    "      lower(translate(coalesce(combustivel,''),\n",
    "        'Ã¡Ã Ã¢Ã£Ã¤Ã©Ã¨ÃªÃ«Ã­Ã¬Ã®Ã¯Ã³Ã²Ã´ÃµÃ¶ÃºÃ¹Ã»Ã¼Ã§ÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃ',\n",
    "        'aaaaaeeeeiiiiooooouuuucAAAAAEEEEIIIIOOOOOUUUUC')),\n",
    "      '[^a-z]', ''\n",
    "    ) AS s\n",
    "  FROM sc_silver.viaturas\n",
    ")\n",
    "SELECT\n",
    "  CASE\n",
    "    WHEN s RLIKE 'plugin|plug'                         THEN 'HÃ­brido Plug-in'\n",
    "    WHEN s RLIKE 'hibrid' AND s RLIKE '(gasoleo|diesel)' THEN 'HÃ­brido GasÃ³leo'\n",
    "    WHEN (s RLIKE 'hibrid' AND s RLIKE 'gasolin')\n",
    "         OR s RLIKE '(electrico|eletrico)gasolina|gasolina(electrico|eletrico)'\n",
    "                                                      THEN 'HÃ­brido Gasolina'\n",
    "    WHEN s RLIKE 'hibrid'                              THEN 'HÃ­brido'\n",
    "    WHEN s RLIKE 'gpl' AND s RLIKE 'gasolin'           THEN 'Gasolina/GPL'\n",
    "    WHEN s = 'gpl'                                     THEN 'GPL'\n",
    "    WHEN s RLIKE 'electri'                             THEN 'ElÃ©trico'\n",
    "    WHEN s RLIKE 'diesel|gasoleo'                      THEN 'GasÃ³leo'\n",
    "    WHEN s RLIKE 'gasolin'                             THEN 'Gasolina'\n",
    "    WHEN s = '' OR s IN ('na','nd') OR s RLIKE 'semespecificar'\n",
    "                                                      THEN NULL\n",
    "    ELSE NULL\n",
    "  END AS combustivel_norm,\n",
    "  COUNT(*) AS cnt\n",
    "FROM src\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b122758a-c3d7-4da4-8aed-7b3f9a5374cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT combustivel, COUNT(*) AS cnt\n",
    "FROM sc_silver.viaturas\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a60b1eaa-0dd9-464c-9b50-43a71ec5a485",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "WITH src AS (\n",
    "  SELECT\n",
    "    tire_source AS raw,\n",
    "    regexp_replace(\n",
    "      lower(translate(coalesce(tire_source,''),\n",
    "        'Ã¡Ã Ã¢Ã£Ã¤Ã©Ã¨ÃªÃ«Ã­Ã¬Ã®Ã¯Ã³Ã²Ã´ÃµÃ¶ÃºÃ¹Ã»Ã¼Ã§ÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃ',\n",
    "        'aaaaaeeeeiiiiooooouuuucAAAAAEEEEIIIIOOOOOUUUUC')),\n",
    "      '[^a-z]', ''\n",
    "    ) AS s\n",
    "  FROM sc_silver.viaturas\n",
    ")\n",
    "SELECT\n",
    "  CASE\n",
    "    WHEN s RLIKE '(hank.*kumho|kumho.*hank|hank.*nexen|nexen.*hank|kumho.*nexen|nexen.*kumho)'\n",
    "         THEN NULL                                 -- vÃ¡rias marcas conhecidas na mesma cÃ©lula\n",
    "    WHEN s RLIKE 'dunlop'                          THEN 'Michelin'\n",
    "    WHEN s RLIKE 'continental'                     THEN 'Continental'\n",
    "    WHEN s RLIKE 'michelin|micheline|michelinsport|^mich$|^mich' THEN 'Michelin'\n",
    "    WHEN s RLIKE 'hank|han?kook'                   THEN 'Hankook'\n",
    "    WHEN s RLIKE 'nexen'                           THEN 'Nexen'\n",
    "    WHEN s RLIKE 'pirel'                           THEN 'Pirelli'\n",
    "    WHEN s RLIKE 'kumh|kumho'                      THEN 'Kumho'\n",
    "    WHEN s RLIKE 'bridgestone'                     THEN 'Bridgestone'\n",
    "    WHEN s = '' OR s IN ('na','nd')                THEN NULL\n",
    "    ELSE NULL\n",
    "  END AS tire_source_norm,\n",
    "  COUNT(*) AS cnt\n",
    "FROM src\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "130b1677-4982-44a6-860a-6dd6a1e7e6b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT tire_source, COUNT(*) AS cnt\n",
    "FROM sc_silver.viaturas\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adc02837-e206-4a5d-b0e7-c9e9444f5305",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT codigo_local, COUNT(*) AS cnt\n",
    "FROM sc_silver.viaturas\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8955b71-b4d5-4a57-a20f-675613ec4c46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "WITH src AS (\n",
    "  SELECT\n",
    "    gwms_combustivel AS raw,\n",
    "    -- normaliza: minÃºsculas, remove acentos e tudo o que nÃ£o Ã© letra\n",
    "    regexp_replace(\n",
    "      lower(translate(coalesce(gwms_combustivel,''),\n",
    "        'Ã¡Ã Ã¢Ã£Ã¤Ã©Ã¨ÃªÃ«Ã­Ã¬Ã®Ã¯Ã³Ã²Ã´ÃµÃ¶ÃºÃ¹Ã»Ã¼Ã§ÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃ',\n",
    "        'aaaaaeeeeiiiiooooouuuucAAAAAEEEEIIIIOOOOOUUUUC')),\n",
    "      '[^a-z]', ''\n",
    "    ) AS s\n",
    "  FROM sc_silver.viaturas\n",
    ")\n",
    "SELECT\n",
    "  CASE\n",
    "    WHEN s RLIKE 'electr'                                    THEN 'ElÃ©trico'\n",
    "    WHEN s RLIKE 'diesel|dsl|tdi'                            THEN 'GasÃ³leo'\n",
    "    WHEN s RLIKE 'liquefiedpetrolg|liquifiedpetrolg|lpg|gpl' THEN 'GPL'\n",
    "    WHEN s RLIKE 'unleaded|gasolin|petrol|lead'              THEN 'Gasolina'\n",
    "    ELSE NULL\n",
    "  END AS combustivel_norm,\n",
    "  COUNT(*) AS cnt\n",
    "FROM src\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49d1f362-9d9c-4926-b804-eecae3b672fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT gwms_combustivel, COUNT(*) AS cnt\n",
    "FROM sc_silver.viaturas\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a977298-d1eb-4c29-b5b5-5a311e0809db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, MapType, StructType\n",
    "\n",
    "tbl = \"sc_silver.viaturas_demo\"\n",
    "TOP_N = 100        # adjust or remove .limit() below\n",
    "INCLUDE_NULLS = False\n",
    "\n",
    "df = spark.table(tbl)\n",
    "\n",
    "# Columns we can group on directly\n",
    "simple_cols = [f.name for f in df.schema.fields\n",
    "               if not isinstance(f.dataType, (ArrayType, MapType, StructType))]\n",
    "\n",
    "for c in simple_cols:\n",
    "    q = df.select(c)\n",
    "    if not INCLUDE_NULLS:\n",
    "        q = q.where(F.col(c).isNotNull())\n",
    "    print(f\"=== {tbl}.{c} ===\")\n",
    "    display(\n",
    "        q.groupBy(F.col(c)).count()\n",
    "         .orderBy(F.desc(\"count\"))\n",
    "         .limit(TOP_N)\n",
    "         .withColumnRenamed(c, \"value\")\n",
    "         .select(\"value\", \"count\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc8aebf6-db84-4c11-83f4-dd34235a854b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT combustivel, COUNT(*) AS cnt\n",
    "FROM sc_silver.viaturas_demo\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e47d86d-a9f7-41e7-a48b-8ebef0978552",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT combustivel, COUNT(*) AS cnt\n",
    "FROM sc_silver.viaturas_demo\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21533dd6-5742-42f9-bfe0-2e22cc75af3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, MapType, StructType\n",
    "\n",
    "tbl = \"sc_silver.bd_rede_hyundai\"\n",
    "TOP_N = 100        # adjust or remove .limit() below\n",
    "INCLUDE_NULLS = False\n",
    "\n",
    "df = spark.table(tbl)\n",
    "\n",
    "# Only columns we can group on directly\n",
    "simple_cols = [f.name for f in df.schema.fields\n",
    "               if not isinstance(f.dataType, (ArrayType, MapType, StructType))]\n",
    "\n",
    "for c in simple_cols:\n",
    "    q = df.select(c)\n",
    "    if not INCLUDE_NULLS:\n",
    "        q = q.where(F.col(c).isNotNull())\n",
    "    print(f\"=== {tbl}.{c} ===\")\n",
    "    display(\n",
    "        q.groupBy(F.col(c)).count()\n",
    "         .orderBy(F.desc(\"count\"))\n",
    "         .limit(TOP_N)\n",
    "         .withColumnRenamed(c, \"value\")\n",
    "         .select(\"value\", \"count\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89dc951b-0df5-4a55-9e40-d89777b347e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, MapType, StructType\n",
    "\n",
    "tbl = \"sc_silver.campaigns\"\n",
    "TOP_N = 100        # adjust or remove .limit() below\n",
    "INCLUDE_NULLS = False\n",
    "\n",
    "df = spark.table(tbl)\n",
    "\n",
    "# Only columns we can group on directly\n",
    "simple_cols = [f.name for f in df.schema.fields\n",
    "               if not isinstance(f.dataType, (ArrayType, MapType, StructType))]\n",
    "\n",
    "for c in simple_cols:\n",
    "    q = df.select(c)\n",
    "    if not INCLUDE_NULLS:\n",
    "        q = q.where(F.col(c).isNotNull())\n",
    "    print(f\"=== {tbl}.{c} ===\")\n",
    "    display(\n",
    "        q.groupBy(F.col(c)).count()\n",
    "         .orderBy(F.desc(\"count\"))\n",
    "         .limit(TOP_N)\n",
    "         .withColumnRenamed(c, \"value\")\n",
    "         .select(\"value\", \"count\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6ec1d4f-341a-41a9-9612-f965d1773fa8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, MapType, StructType\n",
    "\n",
    "tbl = \"sc_silver.campanha_vouchers\"\n",
    "TOP_N = 100        # adjust or remove .limit() below\n",
    "INCLUDE_NULLS = False\n",
    "\n",
    "df = spark.table(tbl)\n",
    "\n",
    "# Only columns we can group on directly\n",
    "simple_cols = [f.name for f in df.schema.fields\n",
    "               if not isinstance(f.dataType, (ArrayType, MapType, StructType))]\n",
    "\n",
    "for c in simple_cols:\n",
    "    q = df.select(c)\n",
    "    if not INCLUDE_NULLS:\n",
    "        q = q.where(F.col(c).isNotNull())\n",
    "    print(f\"=== {tbl}.{c} ===\")\n",
    "    display(\n",
    "        q.groupBy(F.col(c)).count()\n",
    "         .orderBy(F.desc(\"count\"))\n",
    "         .limit(TOP_N)\n",
    "         .withColumnRenamed(c, \"value\")\n",
    "         .select(\"value\", \"count\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac4f4e47-4b1a-4052-b91e-d9107459dda3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT oferta_monetaria, COUNT(*) AS cnt\n",
    "FROM sc_silver.campanha_vouchers\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bb9bd75-3b50-4dec-a23c-afe49d2578cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT oferta_percentual, COUNT(*) AS cnt\n",
    "FROM sc_silver.campanha_vouchers\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62afbfe4-7140-4584-9ae2-ca19fe135cbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, MapType, StructType\n",
    "\n",
    "tbl = \"sc_silver.campanhas_tecnicas\"\n",
    "TOP_N = 100        # adjust or remove .limit() below\n",
    "INCLUDE_NULLS = False\n",
    "\n",
    "df = spark.table(tbl)\n",
    "\n",
    "# Only columns we can group on directly\n",
    "simple_cols = [f.name for f in df.schema.fields\n",
    "               if not isinstance(f.dataType, (ArrayType, MapType, StructType))]\n",
    "\n",
    "for c in simple_cols:\n",
    "    q = df.select(c)\n",
    "    if not INCLUDE_NULLS:\n",
    "        q = q.where(F.col(c).isNotNull())\n",
    "    print(f\"=== {tbl}.{c} ===\")\n",
    "    display(\n",
    "        q.groupBy(F.col(c)).count()\n",
    "         .orderBy(F.desc(\"count\"))\n",
    "         .limit(TOP_N)\n",
    "         .withColumnRenamed(c, \"value\")\n",
    "         .select(\"value\", \"count\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2748f43b-f0a9-4a9a-98d7-a899f87c147d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT warranty_start_date, COUNT(*) AS cnt\n",
    "FROM sc_silver.campanhas_tecnicas\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0760021d-3e38-4de3-9086-aca5b23ee4bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, MapType, StructType\n",
    "\n",
    "tbl = \"sc_silver.contactos_importador_pbs\"\n",
    "TOP_N = 100        # adjust or remove .limit() below\n",
    "INCLUDE_NULLS = False\n",
    "\n",
    "df = spark.table(tbl)\n",
    "\n",
    "# Only columns we can group on directly\n",
    "simple_cols = [f.name for f in df.schema.fields\n",
    "               if not isinstance(f.dataType, (ArrayType, MapType, StructType))]\n",
    "\n",
    "for c in simple_cols:\n",
    "    q = df.select(c)\n",
    "    if not INCLUDE_NULLS:\n",
    "        q = q.where(F.col(c).isNotNull())\n",
    "    print(f\"=== {tbl}.{c} ===\")\n",
    "    display(\n",
    "        q.groupBy(F.col(c)).count()\n",
    "         .orderBy(F.desc(\"count\"))\n",
    "         .limit(TOP_N)\n",
    "         .withColumnRenamed(c, \"value\")\n",
    "         .select(\"value\", \"count\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86532007-b600-4ca7-9cda-7acf3526ccfa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT id_contactos, COUNT(*) AS cnt\n",
    "FROM sc_silver.contactos_importador_pbs\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6910c924-0c60-4b61-8b84-b19f3e414606",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, MapType, StructType\n",
    "\n",
    "tbl = \"sc_silver.contactos_pbs\"\n",
    "TOP_N = 100        # adjust or remove .limit() below\n",
    "INCLUDE_NULLS = False\n",
    "\n",
    "df = spark.table(tbl)\n",
    "\n",
    "# Only columns we can group on directly\n",
    "simple_cols = [f.name for f in df.schema.fields\n",
    "               if not isinstance(f.dataType, (ArrayType, MapType, StructType))]\n",
    "\n",
    "for c in simple_cols:\n",
    "    q = df.select(c)\n",
    "    if not INCLUDE_NULLS:\n",
    "        q = q.where(F.col(c).isNotNull())\n",
    "    print(f\"=== {tbl}.{c} ===\")\n",
    "    display(\n",
    "        q.groupBy(F.col(c)).count()\n",
    "         .orderBy(F.desc(\"count\"))\n",
    "         .limit(TOP_N)\n",
    "         .withColumnRenamed(c, \"value\")\n",
    "         .select(\"value\", \"count\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5f66ecc-298c-4d11-a8e8-6795dac68754",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, MapType, StructType\n",
    "\n",
    "tbl = \"sc_silver.contas_importador_pbs\"\n",
    "TOP_N = 100        # adjust or remove .limit() below\n",
    "INCLUDE_NULLS = False\n",
    "\n",
    "df = spark.table(tbl)\n",
    "\n",
    "# Only columns we can group on directly\n",
    "simple_cols = [f.name for f in df.schema.fields\n",
    "               if not isinstance(f.dataType, (ArrayType, MapType, StructType))]\n",
    "\n",
    "for c in simple_cols:\n",
    "    q = df.select(c)\n",
    "    if not INCLUDE_NULLS:\n",
    "        q = q.where(F.col(c).isNotNull())\n",
    "    print(f\"=== {tbl}.{c} ===\")\n",
    "    display(\n",
    "        q.groupBy(F.col(c)).count()\n",
    "         .orderBy(F.desc(\"count\"))\n",
    "         .limit(TOP_N)\n",
    "         .withColumnRenamed(c, \"value\")\n",
    "         .select(\"value\", \"count\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7e7bf64-326f-4428-a7aa-d1911ed99e41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, MapType, StructType\n",
    "\n",
    "tbl = \"sc_silver.contas_pbs\"\n",
    "TOP_N = 100        # adjust or remove .limit() below\n",
    "INCLUDE_NULLS = False\n",
    "\n",
    "df = spark.table(tbl)\n",
    "\n",
    "# Only columns we can group on directly\n",
    "simple_cols = [f.name for f in df.schema.fields\n",
    "               if not isinstance(f.dataType, (ArrayType, MapType, StructType))]\n",
    "\n",
    "for c in simple_cols:\n",
    "    q = df.select(c)\n",
    "    if not INCLUDE_NULLS:\n",
    "        q = q.where(F.col(c).isNotNull())\n",
    "    print(f\"=== {tbl}.{c} ===\")\n",
    "    display(\n",
    "        q.groupBy(F.col(c)).count()\n",
    "         .orderBy(F.desc(\"count\"))\n",
    "         .limit(TOP_N)\n",
    "         .withColumnRenamed(c, \"value\")\n",
    "         .select(\"value\", \"count\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c81b0167-1ef3-42a6-8d40-d3c524c7e0f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, MapType, StructType\n",
    "\n",
    "tbl = \"sc_silver.contratos_financiamento\"\n",
    "TOP_N = 100        # adjust or remove .limit() below\n",
    "INCLUDE_NULLS = False\n",
    "\n",
    "df = spark.table(tbl)\n",
    "\n",
    "# Only columns we can group on directly\n",
    "simple_cols = [f.name for f in df.schema.fields\n",
    "               if not isinstance(f.dataType, (ArrayType, MapType, StructType))]\n",
    "\n",
    "for c in simple_cols:\n",
    "    q = df.select(c)\n",
    "    if not INCLUDE_NULLS:\n",
    "        q = q.where(F.col(c).isNotNull())\n",
    "    print(f\"=== {tbl}.{c} ===\")\n",
    "    display(\n",
    "        q.groupBy(F.col(c)).count()\n",
    "         .orderBy(F.desc(\"count\"))\n",
    "         .limit(TOP_N)\n",
    "         .withColumnRenamed(c, \"value\")\n",
    "         .select(\"value\", \"count\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5df29ec-1d5b-4e0d-8f0e-656286d869ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT capital_em_divida, COUNT(*) AS cnt\n",
    "FROM sc_silver.contratos_financiamento\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c68b1a5f-09fe-4b77-a8b4-41f7598d0790",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT valor_final, COUNT(*) AS cnt\n",
    "FROM sc_silver.contratos_financiamento\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fd031f0-6a46-47d5-b909-75151599d62f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, MapType, StructType\n",
    "\n",
    "tbl = \"sc_silver.deals\"\n",
    "TOP_N = 100        # adjust or remove .limit() below\n",
    "INCLUDE_NULLS = False\n",
    "\n",
    "df = spark.table(tbl)\n",
    "\n",
    "# Only columns we can group on directly\n",
    "simple_cols = [f.name for f in df.schema.fields\n",
    "               if not isinstance(f.dataType, (ArrayType, MapType, StructType))]\n",
    "\n",
    "for c in simple_cols:\n",
    "    q = df.select(c)\n",
    "    if not INCLUDE_NULLS:\n",
    "        q = q.where(F.col(c).isNotNull())\n",
    "    print(f\"=== {tbl}.{c} ===\")\n",
    "    display(\n",
    "        q.groupBy(F.col(c)).count()\n",
    "         .orderBy(F.desc(\"count\"))\n",
    "         .limit(TOP_N)\n",
    "         .withColumnRenamed(c, \"value\")\n",
    "         .select(\"value\", \"count\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d351e84-5025-4f67-9858-34639fec6773",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, MapType, StructType\n",
    "\n",
    "tbl = \"sc_silver.historico_de_servicos\"\n",
    "TOP_N = 100        # adjust or remove .limit() below\n",
    "INCLUDE_NULLS = False\n",
    "\n",
    "df = spark.table(tbl)\n",
    "\n",
    "# Only columns we can group on directly\n",
    "simple_cols = [f.name for f in df.schema.fields\n",
    "               if not isinstance(f.dataType, (ArrayType, MapType, StructType))]\n",
    "\n",
    "for c in simple_cols:\n",
    "    q = df.select(c)\n",
    "    if not INCLUDE_NULLS:\n",
    "        q = q.where(F.col(c).isNotNull())\n",
    "    print(f\"=== {tbl}.{c} ===\")\n",
    "    display(\n",
    "        q.groupBy(F.col(c)).count()\n",
    "         .orderBy(F.desc(\"count\"))\n",
    "         .limit(TOP_N)\n",
    "         .withColumnRenamed(c, \"value\")\n",
    "         .select(\"value\", \"count\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "baff2a3d-158a-4917-9015-956bb487a469",
     "showTitle": false,
     "tableResultSettingsMap": {
      "5": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"value\":190},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755460096628}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 5
      }
     },
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, MapType, StructType\n",
    "\n",
    "tbl = \"sc_silver.leads_pbs\"\n",
    "TOP_N = 100        # adjust or remove .limit() below\n",
    "INCLUDE_NULLS = False\n",
    "\n",
    "df = spark.table(tbl)\n",
    "\n",
    "# Only columns we can group on directly\n",
    "simple_cols = [f.name for f in df.schema.fields\n",
    "               if not isinstance(f.dataType, (ArrayType, MapType, StructType))]\n",
    "\n",
    "for c in simple_cols:\n",
    "    q = df.select(c)\n",
    "    if not INCLUDE_NULLS:\n",
    "        q = q.where(F.col(c).isNotNull())\n",
    "    print(f\"=== {tbl}.{c} ===\")\n",
    "    display(\n",
    "        q.groupBy(F.col(c)).count()\n",
    "         .orderBy(F.desc(\"count\"))\n",
    "         .limit(TOP_N)\n",
    "         .withColumnRenamed(c, \"value\")\n",
    "         .select(\"value\", \"count\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f689cf68-fab0-4fd9-8340-792819cc980a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT lead_status, COUNT(*) AS cnt\n",
    "FROM sc_silver.leads_pbs\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cadbecc-1b96-4696-a7c4-ba50068b1f48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT consentimento, COUNT(*) AS cnt\n",
    "FROM sc_silver.leads_pbs\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce84af98-5708-44b4-a631-cf641969aa91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT concessao, COUNT(*) AS cnt\n",
    "FROM sc_silver.leads_pbs\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfe9eda8-12bf-47c9-bd16-ea37952327b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, MapType, StructType\n",
    "\n",
    "tbl = \"sc_silver.propostas_realizadas\"\n",
    "TOP_N = 100        # adjust or remove .limit() below\n",
    "INCLUDE_NULLS = False\n",
    "\n",
    "df = spark.table(tbl)\n",
    "\n",
    "# Only columns we can group on directly\n",
    "simple_cols = [f.name for f in df.schema.fields\n",
    "               if not isinstance(f.dataType, (ArrayType, MapType, StructType))]\n",
    "\n",
    "for c in simple_cols:\n",
    "    q = df.select(c)\n",
    "    if not INCLUDE_NULLS:\n",
    "        q = q.where(F.col(c).isNotNull())\n",
    "    print(f\"=== {tbl}.{c} ===\")\n",
    "    display(\n",
    "        q.groupBy(F.col(c)).count()\n",
    "         .orderBy(F.desc(\"count\"))\n",
    "         .limit(TOP_N)\n",
    "         .withColumnRenamed(c, \"value\")\n",
    "         .select(\"value\", \"count\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d966525-285e-4ce7-aaf8-402efb9cb51a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "WITH m AS (\n",
    "  SELECT\n",
    "    gestor_area AS raw,\n",
    "    trim(\n",
    "      regexp_replace(\n",
    "        -- 1) remove any email\n",
    "        regexp_replace(coalesce(gestor_area,''), '(?i)[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,}', ''),\n",
    "        -- 2) if there is a dash leftover (\"Name - ...\"), keep only the part before the dash\n",
    "        '^\\\\s*(.*?)(?:\\\\s*[-ââ].*)?$', '\\\\1'\n",
    "      )\n",
    "    ) AS cleaned\n",
    "  FROM sc_silver.propostas_realizadas\n",
    "  WHERE gestor_area IS NOT NULL AND regexp_like(gestor_area, '(?i)@')\n",
    ")\n",
    "SELECT raw, cleaned, count(*) AS cnt\n",
    "FROM m\n",
    "GROUP BY raw, cleaned\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c0226a7-0a02-4c6a-b995-c3e677dee7ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT gestor_area, COUNT(*) AS cnt\n",
    "FROM sc_silver.propostas_realizadas\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98ba6921-053d-4fca-9c05-99410d9bdbc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT gestor_area, COUNT(*) AS cnt\n",
    "FROM sc_silver.propostas_realizadas\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bd99bf7-56ae-4115-a75e-742a81250102",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT tylacode, COUNT(*) AS cnt\n",
    "FROM sc_silver.propostas_realizadas\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c96f90ac-5f75-4fe1-8ce1-24dad568055d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "TBL = \"sc_silver.propostas_realizadas\"\n",
    "\n",
    "df = spark.table(TBL)\n",
    "delta = DeltaTable.forName(spark, TBL)\n",
    "\n",
    "def is_exact_zero_string(colname: str):\n",
    "    # true only when the text is exactly \"0\" (ignoring surrounding spaces)\n",
    "    return F.trim(F.col(colname).cast(\"string\")) == F.lit(\"0\")\n",
    "\n",
    "updates = []\n",
    "for f in df.schema.fields:\n",
    "    c, dt = f.name, f.dataType\n",
    "\n",
    "    # skip complex types\n",
    "    if isinstance(dt, (ArrayType, MapType, StructType)):\n",
    "        continue\n",
    "\n",
    "    if isinstance(dt, (ByteType, ShortType, IntegerType, LongType, FloatType, DoubleType)):\n",
    "        cond = (F.col(c) == F.lit(0).cast(dt))\n",
    "    elif isinstance(dt, DecimalType):\n",
    "        cond = (F.col(c) == F.lit(0).cast(dt))\n",
    "    elif isinstance(dt, StringType):\n",
    "        cond = is_exact_zero_string(c)   # ONLY \"0\" exactly\n",
    "    else:\n",
    "        # dates/timestamps/booleans/etc. â ignore\n",
    "        continue\n",
    "\n",
    "    updates.append((c, cond))\n",
    "\n",
    "# (Optional) preview how many rows would be affected per column\n",
    "preview = [(c, spark.table(TBL).where(cond).count()) for c, cond in updates]\n",
    "display(spark.createDataFrame(preview, [\"column\", \"rows_to_null\"]).orderBy(F.desc(\"rows_to_null\")))\n",
    "\n",
    "# Apply: set those exact zeros to NULL, column by column\n",
    "for c, cond in updates:\n",
    "    delta.update(\n",
    "        condition = cond,\n",
    "        set       = {c: F.lit(None)}\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d50f9f8-4a5b-4c2a-b483-93632dc5cf44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT valor_do_apoio_pedido, COUNT(*) AS cnt\n",
    "FROM sc_silver.propostas_realizadas\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cd6cbae-c715-45c6-b72d-7dacbf942244",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT s_g_p_u_, COUNT(*) AS cnt\n",
    "FROM sc_silver.propostas_realizadas\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fee92ce5-666c-4f1f-ac93-0f89674e64ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT valor_do_apoio_pedido, COUNT(*) AS cnt\n",
    "FROM sc_silver.propostas_realizadas\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb92b20e-9b37-4c7d-8a9d-f96fbbdb31cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT `probability____`, COUNT(*) AS cnt\n",
    "FROM sc_silver.deals\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f558402f-6dce-4bd2-b58a-c8d4d23abe3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT `n__matriculas_por_associar`, COUNT(*) AS cnt\n",
    "FROM sc_silver.deals\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "617a18ff-29cd-41f0-af40-ae669fb01f0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT `n__matriculas_associadas`, COUNT(*) AS cnt\n",
    "FROM sc_silver.deals\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5d94965-c619-466c-ad5e-9f980f2fdbe9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "/*********************************************\n",
    "SELECT `n__matriculas_por_associar`, COUNT(*) AS cnt\n",
    "FROM sc_silver.deals\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n",
    "\n",
    "-- sanity check there are no negatives left\n",
    "SELECT COUNT(*) AS negatives_left\n",
    "FROM sc_silver.deals\n",
    "WHERE COALESCE(\n",
    "        try_cast(`n__matriculas_por_associar` AS BIGINT),\n",
    "        try_cast(regexp_replace(trim(CAST(coalesce(`n__matriculas_por_associar`,'') AS STRING)),\n",
    "                                '[^0-9-]', '') AS BIGINT)\n",
    "      ) < 0;\n",
    "*********************************************/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22e49e9c-6d1c-4375-a02c-ee78fead2636",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, MapType, StructType\n",
    "\n",
    "tbl = \"sc_silver.viaturas\"\n",
    "TOP_N = 100        # adjust or remove .limit() below\n",
    "INCLUDE_NULLS = False\n",
    "\n",
    "df = spark.table(tbl)\n",
    "\n",
    "# Only columns we can group on directly\n",
    "simple_cols = [f.name for f in df.schema.fields\n",
    "               if not isinstance(f.dataType, (ArrayType, MapType, StructType))]\n",
    "\n",
    "for c in simple_cols:\n",
    "    q = df.select(c)\n",
    "    if not INCLUDE_NULLS:\n",
    "        q = q.where(F.col(c).isNotNull())\n",
    "    print(f\"=== {tbl}.{c} ===\")\n",
    "    display(\n",
    "        q.groupBy(F.col(c)).count()\n",
    "         .orderBy(F.desc(\"count\"))\n",
    "         .limit(TOP_N)\n",
    "         .withColumnRenamed(c, \"value\")\n",
    "         .select(\"value\", \"count\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd1c4f67-e86e-4ce0-9aca-87c8e90f4ca3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Preview how many rows match (should be > 0)\n",
    "SELECT COUNT(*) AS matches\n",
    "FROM sc_silver.viaturas\n",
    "WHERE regexp_like(\n",
    "  CAST(coalesce(viatura_owner_name,'') AS STRING),\n",
    "  '(?i)^\\\\s*admin(?:\\\\s*[-_]*\\\\s*hpk)?\\\\s*$'\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dee7c8f-f127-425b-9047-8f3aa11a31e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT viatura_owner_name, COUNT(*) AS cnt\n",
    "FROM sc_silver.viaturas\n",
    "GROUP BY 1\n",
    "ORDER BY cnt DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbdb1bc4-908c-4fb5-80d3-335397279700",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, MapType, StructType\n",
    "\n",
    "tbl = \"sc_silver.viaturas_demo\"\n",
    "TOP_N = 100        # adjust or remove .limit() below\n",
    "INCLUDE_NULLS = False\n",
    "\n",
    "df = spark.table(tbl)\n",
    "\n",
    "# Only columns we can group on directly\n",
    "simple_cols = [f.name for f in df.schema.fields\n",
    "               if not isinstance(f.dataType, (ArrayType, MapType, StructType))]\n",
    "\n",
    "for c in simple_cols:\n",
    "    q = df.select(c)\n",
    "    if not INCLUDE_NULLS:\n",
    "        q = q.where(F.col(c).isNotNull())\n",
    "    print(f\"=== {tbl}.{c} ===\")\n",
    "    display(\n",
    "        q.groupBy(F.col(c)).count()\n",
    "         .orderBy(F.desc(\"count\"))\n",
    "         .limit(TOP_N)\n",
    "         .withColumnRenamed(c, \"value\")\n",
    "         .select(\"value\", \"count\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca48d67c-2999-49e3-9bbe-ce5cc6e1aefe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Drop specific tables\n",
    "DROP TABLE IF EXISTS sc_silver.funil;\n",
    "\n",
    "DROP TABLE IF EXISTS sc_silver.campaigns_renamed;\n",
    "DROP TABLE IF EXISTS sc_silver.contactos_renamed;\n",
    "DROP TABLE IF EXISTS sc_silver.deals_renamed;\n",
    "DROP TABLE IF EXISTS sc_silver.leads_renamed;\n",
    "DROP TABLE IF EXISTS sc_silver.propostas_realizadas_renamed;\n",
    "\n",
    "DROP TABLE IF EXISTS sc_silver.deals_with_campaigns;\n",
    "DROP TABLE IF EXISTS sc_silver.leads_with_contactos;\n",
    "DROP TABLE IF EXISTS sc_silver.propostas_with_deals_with_campaigns;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6b14b1d-24f3-47a8-8f9b-be8fe22fe707",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DROP TABLE IF EXISTS sc_silver.campaigns_cleaned;\n",
    "DROP TABLE IF EXISTS sc_silver.contactos_cleaned;\n",
    "DROP TABLE IF EXISTS sc_silver.deals_cleaned;\n",
    "DROP TABLE IF EXISTS sc_silver.leads_cleaned;\n",
    "DROP TABLE IF EXISTS sc_silver.propostas_realizadas_cleaned;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3143172-2182-4918-b12f-dd5eb6c5851f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DROP TABLE IF EXISTS sc_silver.bd_rede_hyundai_cleaned;\n",
    "DROP TABLE IF EXISTS sc_silver.campanha_vouchers_cleaned;\n",
    "DROP TABLE IF EXISTS sc_silver.campanhas_tecnicas_cleaned;\n",
    "DROP TABLE IF EXISTS sc_silver.contactos_importador_pbs_cleaned;\n",
    "DROP TABLE IF EXISTS sc_silver.contratos_financiamento_cleaned;\n",
    "DROP TABLE IF EXISTS sc_silver.viaturas_cleaned;\n",
    "DROP TABLE IF EXISTS sc_silver.viaturas_demo_cleaned;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5573709077026717,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Notebook_Pedro",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
