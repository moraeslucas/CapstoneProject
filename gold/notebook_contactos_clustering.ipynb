{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58351989-060c-4a08-a807-b237050195a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#'-U' upgrades the package to the latest available version\n",
    "%pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78526232-033b-489e-957c-ba5ec3a4255d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install scikit-learn \n",
    "%pip install pandas \n",
    "%pip install numpy\n",
    "%pip install databricks-vectorsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "015605d2-6546-4d0f-9b77-433121106b1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad3b4d03-505c-49c1-bfd9-795210198da4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import ArrayType, FloatType, StringType, StructType, StructField, LongType\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from databricks.vector_search.client import VectorSearchClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e4d1031-d1ed-4aab-9ecc-4fb3db564bf8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Load contactos data to create behavioral descriptions later on\"\"\"\n",
    "def load_and_preprocess_gold_contactos():\n",
    "    df = spark.table(\"workspace.sc_gold.contactos_pbs\").limit(100)\n",
    "    # Convert to Pandas for easier text processing\n",
    "    df_pd = df.toPandas()\n",
    "    \n",
    "    return df_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78c7dcbf-9d67-4c41-9dc5-963387b2d030",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Transform contactos data into natural language descriptions\"\"\"\n",
    "def create_contactos_descriptions(df):\n",
    "    descriptions = []\n",
    "    \n",
    "    # 'df.iterrows()' to iterate over DataFrame rows as (index, Series) pairs, with this index being ignored due to the '_'\n",
    "    for _, row in df.iterrows():\n",
    "        # Our key behavioral features\n",
    "        origem        = row['origem']         if pd.notna(row['origem']) \\\n",
    "                                              else 'não especificado'\n",
    "        formulario    = row['formulario']     if pd.notna(row['formulario']) \\\n",
    "                                              else 'não especificado'\n",
    "        tipo_de_pedido= row['tipo_de_pedido'] if pd.notna(row['tipo_de_pedido']) \\\n",
    "                                              else 'não especificado'\n",
    "        modelo        = row['modelo']         if pd.notna(row['modelo']) \\\n",
    "                                              else 'não especificado'\n",
    "        consentimento = row['consentimento']  if pd.notna(row['consentimento']) \\\n",
    "                                              else 'não especificado'\n",
    "        email_opt_out = row['email_opt_out']  if pd.notna(row['email_opt_out']) \\\n",
    "                                              else 'não especificado'\n",
    "        agrupamento   = row['agrupamento_cliente'] if pd.notna(row['agrupamento_cliente'])\\\n",
    "                                                   else 'não especificado'\n",
    "        caracterizacao= row['caracterizacao'] if pd.notna(row['caracterizacao']) \\\n",
    "                                              else 'não especificado'\n",
    "        \n",
    "        # And then we create a natural language description in Portuguese\n",
    "        description = f\"Origem do contacto: {origem}, através do formulário {formulario}. \" \\\n",
    "                      f\"Tipo de Pedido: {tipo_de_pedido}, solicitado para um modelo {modelo}. \" \\\n",
    "                      f\"Agrupado em: {agrupamento}, e caracterizado como {caracterizacao}. \" \\\n",
    "                      f\"Status do consentimento: {consentimento}, e a opção para receber email está em {email_opt_out}.\"\n",
    "\n",
    "        descriptions.append(description)\n",
    "    \n",
    "    return descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3896fbc1-8528-4b63-aca3-9c7087fb9f1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Uses SentenceTransformer model from Hugging Face, a Python framework which performs comparably to OpenAI embeddings\"\"\"\n",
    "def generate_embeddings(descriptions, model_name='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    \n",
    "    # Generate the embeddings, meaning the numerical vector representations of contactos descriptions\n",
    "    print(f\"Generating embeddings for {len(descriptions)} Contactos...\")\n",
    "    embeddings = model.encode(descriptions, show_progress_bar=True)\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8772b94b-7873-40d7-bb2b-b1abb45b1195",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Perform K-means clustering with optimal cluster selection\"\"\"\n",
    "def perform_clustering(embeddings, n_clusters_range=range(2, 4)):\n",
    "    best_score = -1\n",
    "    best_k = 2\n",
    "    scores = []\n",
    "    \n",
    "    # Find optimal nº of clusters using the silhouette score\n",
    "    for k in n_clusters_range:\n",
    "        #'n_init=10' runs 10 times with different centroids¹ and picks the best result\n",
    "        #¹They're the algorithm’s guess at where clusters might be\n",
    "        kmeans = KMeans(n_clusters=k, \n",
    "                        random_state=42, \n",
    "                        n_init=10)\n",
    "        #Assigns each embeddings data point to a cluster\n",
    "        cluster_labels = kmeans.fit_predict(embeddings)\n",
    "        #'silhouette_score' measures how well each point fits within its cluster.\n",
    "        score = silhouette_score(embeddings, cluster_labels)\n",
    "        scores.append(score)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "    \n",
    "    # Final clustering with best k\n",
    "    final_kmeans = KMeans(n_clusters=best_k, \n",
    "                          random_state=42, \n",
    "                          n_init=10)\n",
    "    final_labels = final_kmeans.fit_predict(embeddings)\n",
    "    \n",
    "    return final_labels, best_k, best_score, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40ada40c-be75-4afd-b9cb-b7a33ad5ba9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Analyze cluster characteristics\"\"\"\n",
    "def analyze_clusters(df, cluster_labels, descriptions):\n",
    "    df_clustered = df.copy()\n",
    "    df_clustered['labels'] = cluster_labels\n",
    "    df_clustered['descriptions'] = descriptions\n",
    "    \n",
    "    cluster_analysis = {}\n",
    "    # Analyze cluster distributions\n",
    "    #'set' gets all distinct cluster labels, while 'range' lets you iterate over them\n",
    "    for cluster_label in range(len(set(cluster_labels))):\n",
    "        cluster_data = df_clustered[df_clustered['labels'] == cluster_label]\n",
    "        \n",
    "        analysis = {\n",
    "            'size': len(cluster_data),                                  # Nº of rows in the cluster\n",
    "            'percentage': len(cluster_data) / len(df_clustered) * 100,  # Share of this cluster relative to the whole dataset\n",
    "            'top_origem': cluster_data['origem'].value_counts().head(3) # Top 3 most frequent values in the origem column \n",
    "                                                               .to_dict(),\n",
    "            'top_modelo': cluster_data['modelo'].value_counts().head(3) # First 3 most frequent values in the modelo column\n",
    "                                                               .to_dict(),\n",
    "            'top_tipo_cliente': cluster_data['tipo_cliente'].value_counts()\n",
    "                                                            .head(3)    # Top 3 most frequent Contactos types\n",
    "                                                            .to_dict(),   \n",
    "            'sample_descriptions': cluster_data['descriptions'].head(3) #First 3 Contacto descriptions from this cluster\n",
    "                                                               .tolist()  \n",
    "        }\n",
    "\n",
    "        cluster_analysis[f'Cluster_{cluster_label}'] = analysis\n",
    "    \n",
    "    return df_clustered, cluster_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "821e3cdd-05fe-4eff-90a2-81a0e1ec8e8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Create visualizations for cluster analysis\"\"\"\n",
    "def visualize_clusters(embeddings, cluster_labels, best_k):    \n",
    "    #Principal Component Analysis (PCA) reduces high-dimensional data down to 2D, so it can be easier to explore it visually.\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    embeddings_2d = pca.fit_transform(embeddings)\n",
    "    \n",
    "    # Create plots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # PCA plot\n",
    "    scatter = axes[0].scatter(embeddings_2d[:, 0], \n",
    "                              embeddings_2d[:, 1], \n",
    "                              c=cluster_labels, \n",
    "                              cmap='tab10', \n",
    "                              alpha=0.6)\n",
    "    axes[0].set_title(f'Contacto - Clusters (PCA) - {best_k} clusters')\n",
    "    plt.colorbar(scatter, ax=axes[0])\n",
    "    \n",
    "    # Cluster distribution\n",
    "    unique_labels, counts = np.unique(cluster_labels, return_counts=True)\n",
    "    axes[1].bar(unique_labels, counts)\n",
    "    axes[1].set_title('Cluster Distribution')\n",
    "    axes[1].set_xlabel('Cluster ID')\n",
    "    axes[1].set_ylabel('Number of Contactos')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7be4d210-7ebb-40bb-b6d7-cee73d753fd7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Create visualizations for cluster analysis, excluding the noise (i.e., outlier cluster)\"\"\"\n",
    "def visualize_clusters_optimized(embeddings, cluster_labels, best_k):\n",
    "    unique_labels, counts = np.unique(cluster_labels, return_counts=True)\n",
    "    # Identify the outliers\n",
    "    smallest_indices = np.argsort(counts)[:3]  # Get indices of 2 smallest clusters\n",
    "    smallest_cluster_ids = unique_labels[smallest_indices]\n",
    "    # smallest_cluster_id = unique_labels[np.argmin(counts)]\n",
    "    \n",
    "    # Filter out this outlier\n",
    "    mask = ~np.isin(cluster_labels, smallest_cluster_ids)\n",
    "    # mask = cluster_labels != smallest_cluster_id\n",
    "    # Applies the mask to the embeddings array, meaning it keeps the embeddings that don’t belong to the outlier cluster.\n",
    "    filtered_embeddings = embeddings[mask]\n",
    "    filtered_labels = cluster_labels[mask]\n",
    "    \n",
    "    # Update remaining cluster labels to be contiguous (0, 1, 2, ...)\n",
    "    label_mapping = {old_label: new_label for new_label, old_label in \n",
    "                    enumerate(np.unique(filtered_labels))}\n",
    "    mapped_labels = np.array([label_mapping[label] for label in filtered_labels])\n",
    "    \n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    embeddings_2d = pca.fit_transform(filtered_embeddings)\n",
    "    \n",
    "    # Create plots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # PCA plot\n",
    "    scatter = axes[0].scatter(embeddings_2d[:, 0], \n",
    "                              embeddings_2d[:, 1], \n",
    "                              c=mapped_labels, \n",
    "                              cmap='tab10', \n",
    "                              alpha=0.6)\n",
    "    axes[0].set_title(f'Contacto - Clusters (PCA) - {best_k-3} clusters')\n",
    "    plt.colorbar(scatter, ax=axes[0])\n",
    "    \n",
    "    # Cluster distribution\n",
    "    filtered_unique_labels, filtered_counts = np.unique(mapped_labels, return_counts=True)\n",
    "    axes[1].bar(filtered_unique_labels, filtered_counts)\n",
    "    axes[1].set_title('Cluster Distribution')\n",
    "    axes[1].set_xlabel('Cluster ID')\n",
    "    axes[1].set_ylabel('Number of Contactos')\n",
    "       \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d09dec22-162f-4eed-b20a-f99ca1abe488",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--This table (which is updated in the next cell) has a PK so it can be used as a feature table\n",
    "CREATE OR REPLACE TABLE workspace.sc_gold.contactos_pbs_embeddings (\n",
    "    id BIGINT NOT NULL PRIMARY KEY,\n",
    "    description STRING,\n",
    "    embedding ARRAY<FLOAT>\n",
    ") USING DELTA;\n",
    "\n",
    "\n",
    "ALTER TABLE workspace.sc_gold.contactos_pbs_embeddings \n",
    "SET TBLPROPERTIES (delta.enableChangeDataFeed = true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb4fc50c-292a-4fb9-a8f2-797ce59fec83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Main function to execute the clustering pipeline\"\"\"\n",
    "\n",
    "print(\"Loading contactos data...\")\n",
    "contacto_df = load_and_preprocess_gold_contactos()\n",
    "\n",
    "print(\"Creating contactos behavioral descriptions...\")\n",
    "contacto_descriptions = create_contactos_descriptions(contacto_df)\n",
    "\n",
    "print(\"Generating embeddings...\")\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "embeddings = generate_embeddings(contacto_descriptions)\n",
    "\n",
    "# First, convert to Pandas DataFrame\n",
    "pdf = pd.DataFrame({\n",
    "    \"id\": range(1, len(contacto_descriptions) + 1),\n",
    "    \"description\": contacto_descriptions,\n",
    "    \"embedding\": embeddings.tolist()  # convert numpy arrays to Python lists\n",
    "})\n",
    "# Respective schema for this Spark DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"id\", LongType(), False), \n",
    "    StructField(\"description\", StringType(), True),\n",
    "    StructField(\"embedding\", ArrayType(FloatType()), True)\n",
    "])\n",
    "df = spark.createDataFrame(pdf, schema=schema)\n",
    "\n",
    "# Lastly, save as a Delta table\n",
    "print(\"Creating contactos_pbs_embeddings table...\")\n",
    "df.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .saveAsTable(\"workspace.sc_gold.contactos_pbs_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56aa707f-dd54-4b0c-92f9-3666b3de52b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "%sql\n",
    "--Determininig/Confirming the embedding dimension for the sentence-transformers LM model \n",
    "SELECT size(embedding) as embedding_dimension \n",
    "FROM workspace.sc_gold.contactos_pbs_embeddings \n",
    "LIMIT 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c4b16be-cd1f-4332-9ad7-e5fceb8883a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "vsc = VectorSearchClient()\n",
    "\n",
    "# Create a Vector Search (i.e., a type of search optimized to retrieve embeddings) index on the embedding column\n",
    "vsc.create_delta_sync_index(\n",
    "    endpoint_name=\"contactos_pbs_embeddings\",\n",
    "    index_name=\"workspace.sc_gold.contactos_pbs_embeddings_index\",\n",
    "    source_table_name=\"workspace.sc_gold.contactos_pbs_embeddings\",\n",
    "    pipeline_type=\"TRIGGERED\", # This index is only updated when the trigger is explicitly sync\n",
    "    primary_key=\"id\",\n",
    "    embedding_vector_column=\"embedding\",\n",
    "    embedding_dimension=384\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a5ef81b-edf2-4285-9cec-76fe79426bc4",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1758770958515}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "disable_notice=True\n",
    "\n",
    "index = vsc.get_index(\n",
    "    endpoint_name=\"contactos_pbs_embeddings\", \n",
    "    index_name=\"workspace.sc_gold.contactos_pbs_embeddings_index\"\n",
    ")\n",
    "\n",
    "results = index.similarity_search(\n",
    "    num_results=99,\n",
    "    columns=[\"id\", \"embedding\"],\n",
    "    query_vector=embeddings[77].tolist()\n",
    ")\n",
    "\n",
    "fair_matches = []\n",
    "for result in results['result']['data_array']:\n",
    "    # Filter by fair matches only\n",
    "    if result[2] <= 0.15:\n",
    "        fair_matches.append({\n",
    "            'ID': result[0],\n",
    "            'Score': round(result[2], 3),\n",
    "            'Description': result[1]\n",
    "        })\n",
    "df = pd.DataFrame(fair_matches)\n",
    "df = df.sort_values('Score', ascending=True)\n",
    "display(df)\n",
    "\n",
    "print()\n",
    "'''\n",
    "Here is the reference for distance-based scores (used by Databricks Vector Search) in embeddings:\n",
    "\n",
    "< 0.01 = Excellent matches (very similar content)\n",
    "0.01 - 0.05 = Good matches (related content)\n",
    "0.05 - 0.15 = Fair matches (somewhat related)\n",
    "> 0.15 = Poor matches (likely unrelated)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4eed0448-b1de-4e95-aa87-6bcf004ca45e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Performing clustering...\")\n",
    "cluster_labels, best_k, best_score, scores = perform_clustering(embeddings)\n",
    "\n",
    "print(f\"Optimal number of clusters: {best_k}\")\n",
    "print(f\"Best silhouette score: {best_score:.3f}\")\n",
    "print(f\"Silhouette scores for different Ks: {scores}\")\n",
    "\n",
    "print(\"Analyzing clusters...\")\n",
    "clustered_df, cluster_analysis = analyze_clusters(contacto_df, cluster_labels, contacto_descriptions)\n",
    "\n",
    "# Print cluster analysis\n",
    "for cluster_name, analysis in cluster_analysis.items():\n",
    "    print(f\"\\n{cluster_name}:\")\n",
    "    print(f\"  Size: {analysis['size']} ({analysis['percentage']:.1f}%)\")\n",
    "    print(f\"  Top Origins: {analysis['top_origem']}\")\n",
    "    print(f\"  Top Models: {analysis['top_modelo']}\")\n",
    "    print(f\"  Contacto Types: {analysis['top_tipo_cliente']}\")\n",
    "\n",
    "# Visualize results\n",
    "visualize_clusters(embeddings, cluster_labels, best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4aaf8aa-61c7-423d-94c8-83e1b568e840",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Keeping this cell due to its output\"\"\"\n",
    "\n",
    "print(\"Loading contactos data...\")\n",
    "contacto_df = load_and_preprocess_gold_contactos()\n",
    "\n",
    "print(\"Creating contactos behavioral descriptions...\")\n",
    "contacto_descriptions = create_contactos_descriptions(contacto_df)\n",
    "\n",
    "print(\"Generating embeddings...\")\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "embeddings = generate_embeddings(contacto_descriptions)\n",
    "\n",
    "# First, convert to Pandas DataFrame\n",
    "pdf = pd.DataFrame({\n",
    "    \"id\": range(1, len(contacto_descriptions) + 1),\n",
    "    \"description\": contacto_descriptions,\n",
    "    \"embedding\": embeddings.tolist()  # convert numpy arrays to Python lists\n",
    "})\n",
    "# Respective schema for this Spark DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"id\", LongType(), False), \n",
    "    StructField(\"description\", StringType(), True),\n",
    "    StructField(\"embedding\", ArrayType(FloatType()), True)\n",
    "])\n",
    "df = spark.createDataFrame(pdf, schema=schema)\n",
    "\n",
    "# Lastly, save as a Delta table\n",
    "df.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .saveAsTable(\"contactos_pbs_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55374b56-731d-4c0b-aa34-c6ec68ccb1de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Visualize results for 7 clusters (noise removed)\n",
    "visualize_clusters_optimized(embeddings, cluster_labels, best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2db8156-df8f-47e1-9807-18dddd84c8cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Visualize results for 6 clusters (2 outliers removed)\n",
    "visualize_clusters_optimized(embeddings, cluster_labels, best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbda0988-d011-43ee-a98b-84a669eaac46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Visualize results for 5 clusters (more noise removed)\n",
    "visualize_clusters_optimized(embeddings, cluster_labels, best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4aabb550-c717-4509-92c7-63f065b47128",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"To Do\"\"\"\n",
    "#Change the Cluster ID for a significant name\n",
    "#Remove the numbers at the \"PCA plot\""
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": "HIGH"
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8312250017423022,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "notebook_contactos_clustering",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
